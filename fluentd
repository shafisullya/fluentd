Course Introduction
With the growth of large scale, distributed systems the challenges of managing logs has become acute. It is increasingly common to have thousands of nodes and tens of thousands of services all emitting data which needs to be attributed, normalized, and aggregated i.e. "logged" This self-paced, hands-on course is designed to introduce individuals with a technical background to the Fluentd log forwarding and aggregation tool. Fluentd provides fast and efficient log transformation, enrichment, aggregation, and forwarding capabilities. These capabilities enable Fluentd to realize the concept of a "unified logging layer" that helps users consume log data collected from all parts of a large scale, distributed system.

In this course, you will explore the full range of Fluentd operations and features, from installing Fluentd as a native process to running Fluentd in a container, and from using Fluentd as a simple log forwarder to using Fluentd as a sophisticated log aggregator and processor. Upon completion, you will have the skills necessary to deploy Fluentd in a wide range of production settings.

Course Learning Objectives
By the end of this course, you should be able to:

Install and configure Fluentd in cloud native environments.
Configure Fluentd to process log data from multiple inputs.
Configure Fluentd to filter and transform data.
Configure Fluentd to distribute log data to various backends.
Configure Fluentd for high availability and high performance.

Chapter Overview
Fluentd is an open source software solution for collecting, processing and distributing logs. It can be used to implement a unified logging layer, a single solution for visibility into an environment's application and infrastructure health. It is extensible, lean and reliable, with hundreds of plugins that can cover almost any use case.

This chapter will introduce the concept of observability, the features of a unified logging layer, the challenges Fluentd and tools like it attempt to solve, and finally introduce Fluentd itself.


Learning Objectives
By the end of this chapter, you should be able to:

Define the main aspects of observability.
Discuss the need for a central interface for log data.
Examine the properties of the Fluentd log aggregator.
Explore alternatives to Fluentd.
Describe the performance characteristics of Fluentd.
Review installation concerns and methods of deploying Fluentd.

Observability
Observability allows us to "see" the behavior of applications and the infrastructure they run on. Three independent sets of data help create observability:

Logs
Records of discrete events reported by system components (e.g. a user logged in).
Metrics
Streams of numbers that provide measurements over time associated with a particular process or activity (e.g. percent CPU in use).
Traces
Information about an execution path through a system from component to component (e.g. trade service calls audit service).
Logs, metrics and traces are all cross-cutting concerns; best implemented in one way cluster-wide.

Visualization is the fourth leg of the observability stool. Visualization systems display logs, metrics, and trace data with customizable charts, graphs, and tables enabling us to "see" the collected data in multiple dimensions and correlate seemingly unrelated events/messages to assist with root-cause analysis.

Achieving observability in distributed systems requires collecting data from many different producers and layers; from physical systems (blades, network appliances, etc.) to logical layers (hypervisors, guest OSes, applications, etc.). It is more challenging to collect and correlate events and data in distributed systems than in traditional single-host based solutions due to the many hosts potentially involved in a given activity.

Four intersecting circles, each representing one of the observability components: logging, monitoring, tracing and visualization 


Logging
Logs are an important component of observability. They provide a record of discrete events recorded by a given system component. Rich information associated with a wide range of events are reported in logs, depending on verbosity settings (typically customizable):

Informational activities - boot sequences, shutdowns, logins, etc.
Problems - operational errors, stack traces, etc.
Warnings - deprecations, potential problems, etc.
Systems output log data in differing formats that can be structured or informal. For example, the following messages all carry the same information, but use different formats:

"User placed a new order"
Simple log message.
"NewOrder, UID 56749, BUY 800 GSCO MKT"
Same message, more detailed and structured.
"7,56749,1,800,GSCO,8"
Same message, highly structured, field 1 value 7 = "new order request", ...
"0x26 0xFA 0xA4 0x11 0x3D ..."
Same message encoded in binary.
Logs are typically timestamped, allowing them to be correlated with metrics and traces. Correlating system and application events (logs) with system resource utilization (metrics) and user activity (traces) can provide operators with deep insights which can be used to improve system architecture, solve problems, design more efficient applications and more.


Log Example
Below you can see a sample log output:

$ journalctl

-- Logs begin at Tue 2021-05-11 15:51:07 UTC, end at Mon 2021-05-17 14:18:22 UTC. --
May 11 15:51:07 ubuntu kernel: Linux version 5.4.0-1045-aws (buildd@lgw01-amd64-003) (gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)) #47~18.04.1-Ubuntu SMP
May 11 15:51:07 ubuntu kernel: Command line: BOOT_IMAGE=/boot/vmlinuz-5.4.0-1045-aws root=LABEL=cloudimg-rootfs ro console=tty1 console=ttyS0 nvme_core.io_ti
May 11 15:51:07 ubuntu kernel: KERNEL supported cpus:
May 11 15:51:07 ubuntu kernel:   Intel GenuineIntel
May 11 15:51:07 ubuntu kernel:   AMD AuthenticAMD
May 11 15:51:07 ubuntu kernel:   Hygon HygonGenuine
May 11 15:51:07 ubuntu kernel:   Centaur CentaurHauls
May 11 15:51:07 ubuntu kernel:   zhaoxin Shanghai
May 11 15:51:07 ubuntu kernel: x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
May 11 15:51:07 ubuntu kernel: x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
May 11 15:51:07 ubuntu kernel: x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
May 11 15:51:07 ubuntu kernel: x86/fpu: Supporting XSAVE feature 0x008: 'MPX bounds registers'
May 11 15:51:07 ubuntu kernel: x86/fpu: Supporting XSAVE feature 0x010: 'MPX CSR'
May 11 15:51:07 ubuntu kernel: x86/fpu: Supporting XSAVE feature 0x020: 'AVX-512 opmask'
May 11 15:51:07 ubuntu kernel: x86/fpu: Supporting XSAVE feature 0x040: 'AVX-512 Hi256' 
May 11 15:51:07 ubuntu kernel: x86/fpu: Supporting XSAVE feature 0x080: 'AVX-512 ZMM_Hi256'
May 11 15:51:07 ubuntu kernel: x86/fpu: Supporting XSAVE feature 0x200: 'Protection Keys User registers'
May 11 15:51:07 ubuntu kernel: x86/fpu: xstate_offset[2]: 576, xstate_sizes[2]: 256
May 11 15:51:07 ubuntu kernel: x86/fpu: xstate_offset[3]: 832, xstate_sizes[3]: 64
May 11 15:51:07 ubuntu kernel: x86/fpu: xstate_offset[4]: 896, xstate_sizes[4]: 64
May 11 15:51:07 ubuntu kernel: x86/fpu: xstate_offset[5]: 960, xstate_sizes[5]: 64
May 11 15:51:07 ubuntu kernel: x86/fpu: xstate_offset[6]: 1024, xstate_sizes[6]: 512

Container Logging
Everything a containerized application writes to standard output (stdout) and error (stderr) is typically handled and redirected somewhere by the container manager. Most container managers can be configured to forward log data but, by default, they typically write application logs to disk as an artifact of the container (e.g. Docker stores log output in /var/lib/docker/containers/<container-id> by default).

Traditional log data was often written to disk which introduces several problems in cloud native systems:

Containers have ephemeral file systems
Container restarts may cause this data to be lost as "restarting" a container often consists of destroying the old failed container and starting a new one from the container image. Orchestration systems like Kubernetes maintain the logs of the current and most recently terminated container to assist with troubleshooting.
Disks have limited space on worker nodes
When a container manager is configured to write application logs to local files (or left in its default configuration), log rotation is critical to avoid filling up the disk on the host. Standard tools like logrotate can be invoked on a schedule to cycle application container logs. A better option may be to configure the container manager to rotate container logs based on fixed file sizes and counts guaranteeing that the host disk never fills with logs beyond a manageable size. Docker's log-opt flag provides many log rotation configurations.
The diagram illustrates how container logging works within a Kubernetes pod using CRI (the Kubernetes Container Runtime Interface). The container manager launches the containerized process with the stdour/err streams redirected to the container manager which saves the logs in a Kubernetes defined location. The container sends log output to stdout or stderr, whereupon the container manager writes the log messages to the log file. Users may then display the log output through Kubernetes, where the Kubelet (the Kubernetes node agent) reads the log data from the defined log directory.


Logging in Distributed Systems
There are many sources for logs in distributed cloud native environments:

Application logs – messages from applications about requests, responses, application execution errors, etc.
Platform logs – query processing performed by databases, messages received and sent by messaging platforms, etc.
Orchestrator logs – node-level agents like CRI-O, API access logs like the Kubernetes API.
System logs – host OS logs, hypervisor logs, guest OS logs.
Cloud native systems typically rely on host logging for the OS, container manager (dockerd, containerd, CRI-O, etc.), and orchestration node agents (kubelet, etc.). The Linux OS captures OS log data through syslog. The logger command can be used in host based scripts to log to syslog; common functions and libraries can be used in various programming languages to write to syslog on the host as well. The syslog daemon can be used to ship logs from a host/guest to a remote location so that log data can be preserved when ephemeral guest systems are terminated, nodes die unexpectedly, intruders delete local logs, etc. journald is an integral part of systemd (the init system on most Linux distributions) and can be used for local log viewing. syslog solutions can read the journal if it exists and forward it.

Container engines capture log data generated by containerized applications. If the cluster control plane is itself containerized, this means that cluster control plane logs are also being managed by the container manager and can be forwarded with the same technique(s) used to forward all other containerized application logs. In cloud native systems this means that the container engine is potentially the source for logs from everything running above the infrastructure layer (applications, orchestration control plane components, software defined storage and networking daemons, monitoring agents, etc.).

Ideally, cloud native applications and platforms auto-scale using observed metrics, adding and subtracting containers and cluster nodes as load demands. Because containers and cluster nodes are seen as fungible resources, logs from each layer of a cluster should be captured (system, orchestrator, platform services, apps) and have a lifecycle independent from the cluster. Orchestration systems like Kubernetes provide no native storage solution for log data. Many different cluster logging solutions can be integrated. One popular solution is “EFK” (ElasticSearch, Fluentd, Kibana).

 

The diagram illustrates how a variety of data and log sources from a host can all be sent to Fluentd
 

The diagram illustrates how a variety of data and log sources (which include daemons, agents and containers) from a host can all be sent to Fluentd. Fluentd represents a logging layer component, which can then normalize and forward the data to the destination datastore, represented by ElasticSearch in the example.

Next, we will discuss some strategies used to implement distributed logging.


Logging Strategies: Node-level Logging Agent
The most common logging strategy used to implement distributed logging is a node-level logging agent, or node logging agent. Node logging agents are dedicated services that forward logs from nodes to log aggregators or backends. They require access to a directory with log files from all of the application containers on a node. This is the most encouraged approach for cloud native cluster logging and common implementations include: a system controlled service on the node, a Kubernetes DaemonSet pod.

Benefits:

One agent per node to handle container, cluster and node-level logs.
Does not require any changes to the containerized applications running on the node.
Drawbacks:

It only works for containerized applications which log to standard output and standard error.
 

The diagram shows a node logging agent, represented by Logging Agent Pod
 

The diagram shows a node logging agent, represented by Logging Agent Pod, which has access to all of the logs for all applications found on a node. All application container logs are collected by this log agent, which then forwards the logs to a logging backend.

Logging Strategies: In-Pod Streaming Container
An in-pod streaming container reads collocated application logs from a file, socket, stream, etc., shared within the pod. It uses an additional container within the application pod as a helper that standardizes logs from an application container that does not output logs to stdout/stderr or that uses a format inconsistent with the platform’s needs or design.

The streaming container transforms log data as required and emits it to stdout/stderr where it is captured to a node level log file by the container runtime. The logging agent that runs on each node or centrally in the network collects and forwards the node logs from all applications on the node. The streaming container pattern, can be used in combination with an existing node logging agent, allowing pods with and without adapters to coexist.

An in-pod streaming container also enables customization and adjustment of the log stream from an application before it is routed to its final destination. For example, a streaming container can adapt an application coded to write log data to a file to participate in the stdout/err driven log flow of the overall cluster. This is known as the adapter pattern in Kubernetes pod design.

 

In-pod streaming illustrated
 

The Logging Agent Pod depicted in the diagram can also represent a logging agent that exists somewhere else in the network.

Logging Strategies: Pod Local Logging Container
When node security considerations eliminate node local log storage and/or processing as an option, a logging agent can be included in the application container pod.

The main difference between this model and the node agent model, is that in this pattern, the pod logging agent bypasses the node logging agent, forwarding logs to a logging backend or aggregator directly. This solution can be effective when several segregated applications with independent logging systems need to run on the same cluster.

Another important benefit to this pattern is that the application developer or DevOps team responsible for deploying the application have full control over the format, content, and other aspects of the data. Unlike node-level logging agents, which require elevated permissions or centralized, remote log aggregators, a pod local logging container is fully configurable by the user. Thus, the pod local logging container pattern is ideal for developers and DevOps teams who want to wire their application output to a specific logging ecosystem.

The principle drawback is that this approach removes log visibility at the node level, disabling administrative log viewers built into container managers and cluster orchestrators like Kubernetes.

 

The diagram shows the pod local logging container pattern
 

The diagram shows the pod local logging container pattern. It is similar to an in-pod streaming container, except this local logging container submits the application container's logs directly to the logging backend rather than submitting it to a node logging agent.

Unified Logging Layer
The aim of a Unified Logging Layer is to provide a single, uniform log ingestion and distribution solution. This model minimizes overhead associated with log management across systems and applications by aggregating log data under a single solution which supports ingestion and distribution to/from a wide range of tools, applications and users.

As discussed in the "Unified Logging Layer: Turning Data into Action" article by Kiyoto Tamura, a maintainer of Fluentd, a Unified Logging Layer should ideally have the following characteristics: flexibility, supportability, reliability and scalability.

Click on each box to learn more about these features.

Unified Logging Layer Features
Close Flexibility
A flexible interface can be more difficult to manage than a rigid one, but is more adaptable to change as new data sources, destinations and backends are added to the infrastructure, and more compatible with existing applications with predefined log formats.

Close Supportability
A widely supportable interface that all producers and consumers can implement solutions against. JSON is an excellent central document format in this model because, though slower than binary protocols, there are far more applications and storage backends that can natively interoperate with JSON to store data. Example: JSON serialization is slower than binary serialization but has wider support in storage backends.

Close Reliability
It can be achieved by implementing buffering to protect data in transit and redundancy to protect data at rest from external factors, such as natural disasters or technical issues.

Close Scalability
Support for new data inputs and outputs without excessive technical overhead or performance degradation can be achieved through a pluggable architecture that encourages and facilitates reuse and modularity.

The diagram below shows a representation of a Unified Logging Layer. On the right, sources including syslog, Apache/NGINX, Mobile/Web app logs, and Sensors/IoT send data into a central place where filtering, buffering, and routing operations occur. After those operations complete, the outputs of those sources are sent to a variety of destinations, including Treasure Data, MongoDB, Hadoop, ElasticSearch, and cloud provider backends like AWS or GCP.

 

A representation of a Unified Logging Layer


What Is Fluentd?
Fluentd is an open source data aggregator for application log and metrics data, with the goal of providing a practical implementation of the Unified Logging Layer concept (collects, filters, buffers and outputs logs across multiple sources and destinations). It was conceived by Sadayuki "Sada" Furuhashi, a co-founder of Treasure Data, Inc., in 2011. In 2013, Fluentd was recommended as a data collection tool by Amazon Web Services (AWS) and three years later donated to the Cloud Native Computing Foundation (CNCF). It became the fourth project to be donated, and graduated in April of 2019, achieving the highest status within the CNCF. It was also used by GCP's BigQuery as a default logging agent (customized as google-fluentd). The Treasure Data, Inc. team, acquired by ARM Holdings Plc, along with the broader open source community, actively supports and develops the core Fluentd codebase.

Fluentd is:

Extensible (flexible, pluggable and composable)
Lean
Reliable (robust, scalable, highly available)
Click on each box to learn about features provided by Fluentd that help fulfill the promises of the Unified Logging Layer.

Fluentd Features
Close Pluggable Architecture
Written in both C and Ruby, Fluentd can be configured, and if necessary, adapted to the needs of a wide array of users. Counting hundreds of plugins from both the core developers as well as its community, Fluentd provides the extensibility that defines a unified logging layer.

Close JSON Data Format
Fluentd makes use of JSON in as many ways as possible, to facilitate support for the most popular log management backends. This enables extensibility as well due to the broad industry support for JSON across all types of tools.

Close Small Resource Footprint
A minimal footprint is an important aspect of a logging agent that will likely be run on hundreds, or thousands, or hundreds of thousands of systems and in a range of contexts. Fluentd’s small memory and CPU profile allow it to be deployed alongside the applications it is monitoring without interfering with application function.

Close Data Buffering
Buffering minimizes the risk of data loss by moving small amounts of processed data, and retrying failed chunks at given intervals. Fluentd also offers the ability to store those buffers in memory or on local disk.

Close Scalability and High Availability
Fluentd supports configurations where multiple instances of Fluentd interface with each other to create a pipeline of smaller, near- or in-app Fluentd collectors reporting to a master data aggregator. Combined with data buffering, these ensure scalability and reliability. Using a shared-nothing approach at the aggregator layer, multiple Fluentd aggregators can operate in parallel allowing N-1 failures without data loss.



Fluentd's Role
Fluentd is meant to run as a persistent background process where it collects, parses, filters transforms and sends whatever data it is configured to collect to other systems. In this way Fluentd can act as a many to many forwarding agent collecting data from many sources and forwarding selected elements of that data set to various target back ends. It can also run standalone, acting as a master aggregator for logs and data coming from multiple nodes or upstream agents. 

Fluentd is meant to replace collections of individual, point to point scripts and hodgepodges of tools with a single, flexible, reliable agent which can be used to compose a wide range of logging architectures.

The image below illustrates Fluentd's architecture.


Fluentd Source
Fluentd is open source and written in Ruby and C, which combined allow Fluentd to be both flexible, expandable and performant. The performance-critical components of Fluentd, particularly networking and object serialization, are written in C. Ruby acts as a wrapper around the C code, allowing for flexibility and facilitating plugin development. It also allows Fluentd to be distributed as a Ruby gem (gem being the term used for an installable Ruby library).

There are typically two versions of Fluentd available:

Stable
Stable releases are designed for production use. 
Edge
Edge releases incorporate the latest feature additions for development and testing.
Prior to v1.0.0, v0.12 was the most widely used stable release. Some older releases are still documented and made available from the GitHub repository and Fluentd website. Version 1.0.0 uses a new plugin API introduced in v0.14, and is compatible with v0.12 plugins via a compatibility layer. However, Fluentd v0.12 cannot use plugins written for the new API, so it is recommended that most users upgrade to some version within the v1.0 major release.

To learn more, review GitHub Fluentd repository.

Alternatives to Fluentd
There are many alternative and similar solutions to Fluentd, which are also available in both open source and commercially supported distributions.

Click on each box to learn more about these alternatives.

Alternatives to Fluentd
Logstash logoClose Logstash
It is an open source, server-side data processing tool that ingests data from a range of sources simultaneously, transforms it, and sends it to a backend. Logstash, like Fluentd, has a very large plugin library and can handle multiple inputs and outputs. The main difference between Logstash and Fluentd is in resource usage: Logstash is JVM-based and uses considerably more resources. It is part of the ElasticSearch, Logstash and Kibana ("ELK") logging and monitoring stack, though in some cases is replaced by Fluentd to create the "EFK" stack.

Elastic Beats logoClose Elastic Beats
Elastic Beats are a collection of lightweight data shippers created by Elastic. Beats are ideal for data collection on sources with limited resources like IoT devices. All Beats are focused only on data collection and do not provide any advanced data processing capabilities.

Apache Flume logoClose Apache Flume
Apache Flume is an open source distributed service that can also efficiently collect, aggregate and move large amounts of log data. It is written in Java. Unlike Fluentd, it is structured so that most processing activities, which occur prior to routing and buffering in Fluentd, occur in the sink, or output side. Flume features a simple and flexible architecture based on streaming data flows. It emphasizes robustness and fault tolerance with tunable reliability mechanisms and failover and recovery mechanisms.

Logagent logoClose Logagent
It is an open source, lightweight log shipper with out-of-the-box and extensible log parsing, on-disk buffering, secure transport and bulk indexing to ElasticSearch and Logsene. Low memory footprint, async I/O, and low CPU overhead makes it suitable for edge servers, IoT devices, sensors, etc.

rsyslog logoClose rsyslog (rocket-fast system for log processing)
It is an evolution of the syslog logger daemon that expanded over time to accept inputs from a wide variety of sources, process and filter them according to user needs, and then output to sources. Compared to Fluentd, it is much more lightweight and more ideally deployed alongside applications on hosts that have limited resources. In that regard, it is much closer to Fluent Bit.

statsd logoClose statsd
It is a Node.js application, originally conceived to allow Etsy to gather hardware and software metrics for later visualization. It functions by listening for statistics (metrics), mainly counters, timers and gauges, then collecting them into an aggregate. Once collected, the aggregates are then sent over User Datagram Protocol (UDP) or Transmission Control Protocol (TCP) to one or more pluggable backend services. Due to its simplicity, it is extremely fast and most appropriate for collection of application metrics.

syslog-ng logoClose syslog-ng
It is another syslog-based log collector and parser. While it holds feature parity in many cases with rsyslog, syslog-ng is supported on many more platforms than rsyslog, which is generally restricted to Linux and Solaris-based operating systems. Like rsyslog, syslog-ng is closer to Fluent Bit in that it is ideally deployed alongside an application where the host has limited resources. It supports legacy BSD syslog, JSON, and journald message formats (extended with plugins). Its tools and modules can be written in C, Python, Java, Lua, or Perl.

Telegraf logoClose Telegraf
It is a plugin-driven server agent written in Go for collecting and reporting metrics. Telegraf is designed with a minimal memory footprint and a plugin architecture. Compared to Fluentd, it has four different plugin types (including an input from Fluentd itself).

OpenTelemtry logoClose OpenTelemetry
OpenTelemetry is a collection of specifications and programming libraries meant to enable developers to provide standardized observability to their applications. By using OpenTelemetry standards and code, developers can ensure that their applications emit observability data (such as logs, metrics, and tracing) in a way that does not require much processing.


Performance
Fluentd is designed to be fast and efficient. It can forward over 50,000 log events per second on a single commodity server utilizing less than 25% of a single virtual CPU and consuming less than 500MB of RAM. Log traffic patterns and environmental conditions vary widely and can have a dramatic impact on log agent performance, users should always conduct their own performance/load tests.

There are a variety of benchmarks hosted on the Fluentd organization on GitHub. Below you can see a sample result from that repo displaying the rate of writing (in lines per second) from Fluentd into a TLS-enabled instance of Kafka. At 95% CPU use to full load, Fluentd is able to maintain a writing rate of 100,000 lines per second into Kafka before hitting other limitations in the test.

 

Total		
Rate of writing (lines/sec)	CPU (%)	Memory (kB)	Remarks
10	1.0		
100	2.0		
1000	8.4		
10000	43.8		
100000	95.8		
200000	100.0		Dummer I/O limit?
300000	N/A		
400000	N/A		
5247047			Max of dummer tool


Prerequisites and System Configuration Tips
Parts of Fluentd are written in Ruby for flexibility and C for performance. It can be installed under Ruby as a gem (Ruby 1.9.3 and later for 0.12 or Ruby 2.4 and later for 1.0). This is the most universal installation method, though it requires more preparation and management than some system package-based installation methods.

If Fluentd is being built and deployed from source, then Git is required to pull the code from the official repositories. This option is ideal for developers, and also environments where pre-packaged solutions cannot be used due to policy or other restrictions.

Setting up the Network Time Protocol daemon (ntpd) is recommended to prevent invalid timestamps in log data. This can be critical in log processing/troubleshooting scenarios. Accurate time is also critical in cases where Fluentd is communicating over Transport Layer Security (TLS), as TLS handshakes cannot complete with heavily out of sync clocks.

Fluentd solutions often involve large numbers of open files and sockets. On Linux, the file descriptor limit can be checked using the following command: ulimit -n. It is recommended to increase the default number of file descriptors supported on most systems. In general, it is also recommended to set soft and hard limits to 65536 for large deployments in /etc/security/limits.conf:

root soft nofile 65536
root hard nofile 65536
* soft nofile 65536
* hard nofile 65536
Some optimization of the Linux networking features is also helpful in high load environments with many Fluentd instances. Setting:

net.ipv4.tcp_tw_reuse = 1 will reuse an existing connection in the TIME-WAIT state for a new outgoing connection if the new timestamp is strictly bigger than the most recent timestamp recorded for the previous connection; this helps avoid lag between network connections.
net.ipv4.ip_local_port_range = 10240 65535 sets a wide range of client ports, enabling more quadruplets (source address, source port, destination address, destination port), and thus supports a greater amount of connections.
These steps are usually manually managed by the user when setting up Fluentd, and should be taken as general guidance, not the best possible settings for all users.


Fluentd Installation
Fluentd is distributed in two major ways: open source and enterprise. Both distribution channels provide the Fluentd core components and functionality.

Stable versions of Fluentd are deemed production worthy. Stable versions are also distributed in pre-configured, often OS-specific, packages as td-agent. The latest, production-ready versions of Fluentd that are not distributed as td-agent releases are available through Ruby as gems and via Docker container images.

Older stable versions are also made available on the Fluentd website. There was a major change in plugin architectures between the latest stable (1.x.x) and previously stable (0.12.x) versions; 1.x.x releases are compatible with 0.12.x plugins, though the opposite is not true.

A pre-compiled version of Fluentd called td-agent is available from the original developers, who also provide optional commercial support for enterprise customers. This offering provides security features, such as end-to-end encryption and a trusted package model, prompt patch support and enterprise support.

 

FEATURE	FLUENTD	TD-AGENT
QA/Support	Community-driven	
QAed by Fluentd original developers

Commercial support for customers

Installation	Ruby gems	rpm/deb/dmg packages
Configuration	Self-service	Preconfigured with recommended settings
Third party plugins	$ fluent-gem install fluent-plugin-xx	$ /usr/sbin/td-agent-gem install fluent-plugin-xx
/etc/init.d/ scripts	No, user needs to write shell script to set it up	Yes (shipped with .deb and .rpm)
Chef recipe	No	Yes
 

While Fluentd supports a wide variety of platforms, including: many distributions of Linux, macOS, and Windows, it has been most heavily tested and integrated with Linux-based environments, and many plugins and solutions have been developed to enable such deployments, though a significant set of plugins work on other OSes:

td-agent is the pre-built and commercially supported release of Fluentd
OSes with predefined packages:
- Ubuntu 20.04, 18.04, 16.04, 14.04, 12.04 & 10.04 64/32bit
- Debian Jessie, Wheezy & Squeeze 64bit
- Red Hat EL/CentOS 5, 6, 7
- Microsoft Windows msi (v0.14 onward)
- Amazon Linux
- Mac OS X .dmg files
Other methods:
- Bare metal/VM hosts (Ruby gem, Chef recipe, from source)
- Container-based (OCI-complaint images, Kubernetes DaemonSet, Kubernetes Sidecars)


Fluentd Gem Installation
This example demonstrates the installation of Fluentd as a Ruby gem. In addition to Fluentd, the Ruby installation also pulls in various gems to provide Fluentd with additional capabilities.

$ sudo gem install fluentd -N

Fetching: msgpack-1.2.6.gem (100%)
Building native extensions. This could take a while...
Successfully installed msgpack-1.2.6
Fetching: yajl-ruby-1.4.1.gem (100%)
Building native extensions. This could take a while...
Successfully installed yajl-ruby-1.4.1
Fetching: cool.io-1.5.3.gem (100%)
Building native extensions. This could take a while...
Successfully installed cool.io-1.5.3
Fetching: sigdump-0.2.4.gem (100%)
Successfully installed sigdump-0.2.4
Fetching: serverengine-2.1.0.gem (100%)
Successfully installed serverengine-2.1.0
Fetching: http_parser.rb-0.6.0.gem (100%)
Building native extensions. This could take a while...
Successfully installed http_parser.rb-0.6.0
Fetching: thread_safe-0.3.6.gem (100%)
Successfully installed thread_safe-0.3.6
Fetching: tzinfo-1.2.5.gem (100%)
Successfully installed tzinfo-1.2.5
Fetching: tzinfo-data-1.2018.9.gem (100%)
Successfully installed tzinfo-data-1.2018.9
Fetching: strptime-0.2.3.gem (100%)
Building native extensions. This could take a while...
Successfully installed strptime-0.2.3
Fetching: dig_rb-1.0.1.gem (100%)
Successfully installed dig_rb-1.0.1
Fetching: fluentd-1.3.3.gem (100%)
Successfully installed fluentd-1.3.3
Done installing documentation for msgpack, yajl-ruby, cool.io, sigdump, serverengine, http_parser.rb, thread_safe, tzinfo, tzinfo-data, strptime, dig_rb, fluentd after 17 seconds 12 gems installed


Chapter Summary
Logging is an important aspect of observability, providing a discrete record of events.

The Fluentd open source log forwarding and aggregating agent provides a Unified Logging Layer that is:

Extensible: providing a flexible, pluggable architecture
Reliable: offering high availability and scalability
Efficient: high throughput with modest resource consumption.
The Fluentd plugin ecosystem is vast, offering many official and community-supported plugins.

Fluentd can be deployed using package managers, Ruby gems, from source or via container under Docker and Kubernetes.

Chapter Overview
This chapter will introduce and explore how to create a basic, yet functional Fluentd configuration. It will introduce the elements that make up a Fluentd configuration and present the XML-like directives necessary to get Fluentd up and running. In addition to the basic structure of the configuration file, you will be introduced to plugins, and how they are chosen and configured to make Fluentd work for your use case. By the end of this chapter, you should be well-informed about how Fluentd configurations need to be structured.


Learning Objectives
By the end of this chapter, you should be able to:

Examine the structure of Fluentd configuration files.
Understand Fluentd configuration directives.
Create and use common Fluentd configurations.

Fluentd Configuration Files
The Fluentd configuration files contain instructions, known as directives, that tell Fluentd how to process log streams. They determine how Fluentd will work on a given host, allowing a user to determine the route an event will take from a specific input to a specific output.

A Fluentd configuration file is comprised of directives describing Fluentd configuration settings, data sources (inputs), intermediate processing steps (filters) and destinations (outputs).

The simplest configuration files will contain one source (an input Fluentd will consume data from) and one match (a destination Fluentd will send matching data to). It is possible to start Fluentd with an empty configuration file, but it will not process any data. Configuration directives can be decomposed into multiple files and then combined using the @include statement, allowing configuration components to be modularized and reused.

Additional directives include:

filter: defines event processing and transformation rules
system: defines global Fluentd configuration options
label: groups filter and match directives together into labeled pipelines
@include: imports directives in other configuration files.
At least one source and one match should be present in a configuration file. It is possible to start Fluentd with an empty configuration file, but it will not initialize any plugins or process any data. Configuration directives can be decomposed into multiple files and then combined using the @include statement, allowing configuration components to be modularized and reused.

 

Simple Fluentd configuration
 

The diagram above represents a simple Fluentd configuration, with Fluentd forwarding log output to two separate databases. On the left is a block containing a collection of hosts and guests, ranging from daemons and agents to containers. All of the entries in that block represent Fluentd sources.

The center Fluentd block illustrates a “filter". Filters can be used to transform streams of data, producing new, more useful output.

Finally, to the right, are a pair of destinations, representing two of the many systems that Fluentd can write to. Fluentd match directives select data for forwarding, making it possible to send some messages to ElasticSearch and others to MongoDB, or all messages to both, along with many other combinations.


Configuration File Syntax
A configuration file separates directives using XML-like elements, such as:

<source>
...
</source>

Each directive defines a plugin “type” to use, e.g. http in the example below. In addition, comments begin with # and end at the end of the line and built-in parameters defined by Fluentd, like @type, are prefixed with an @:

# A simple config

<source>
  @type http
  port 24220
</source>

<match app>
  @type stdout
</match>

Older versions of Fluentd do not follow this convention but new configuration files should prefix all built-in parameter names with @. This makes it clear which parameters are used by Fluentd and which are used by the directive’s plugin. Plugin specific parameters are used to customize the behavior of the plugin, in the example, the port parameter determines which port the http plugin will listen on.

Source directives are enclosed in a <source> element. Multiple source directives can be listed in a single configuration file. Sources tag their event data in various ways. For example, the http plugin creates tags based on the route posted with the data and the tail plugin requires you to assign tags using a tag parameter (POST /app would tag the posted message body with the “app” tag).

Match directives are enclosed within a <match> element. Match directives remove messages with matching tags from the processing pipeline. Directives following a match directive in a configuration will not see messages processed by a previous match directive. The match in the above example outputs all “app” tagged messages to stdout.


Source Directives
A source directive allows Fluentd to receive messages and create events from the input received. Thus, source directives define the input streams that Fluentd processes.

Each source directive must have a @type argument to define the input plugin to use. Plugins are identified using an abbreviated name which drops the plugin category (in_, out_, filter_, parser_, etc.). For example, the @type forward parameter in a <source> directive will use the in_forward plugin; the in_ prefix is implied because the parameter appears in a <source> (a.k.a. input) directive. The required @type short name can be found in a plugin’s documentation (or on the plugin's GitHub page in the case of third party plugins).

Source directives use input plugins so the in_ is left off of the plugin name in the source directive @type argument. Match directives use output plugins so the out_ is left off of the plugin name in the match directive @type argument.

Multiple source directives can be defined in a configuration file to capture events from multiple sources. They can even be created for the same input stream in order to produce parallel processing pipelines. For example, you can have three source directives that read from the same file but have each send events to different formats or destinations.

One input plugin can be used by multiple source directives to define different inputs. For example, a configuration can define three http sources, each with a different port.

Input plugins can listen, tail or otherwise receive data from a configured source. For example, using the http plugin turns Fluentd into a web server that will listen for data POSTed on a given port.

Plugin-specific parameters follow the @type declaration. Examples include: ports to listen on, files to read/tail and tags to add. The full list of plugin parameters supported by each plugin can be found in the plugin’s documentation.

After Fluentd receives traffic from a configured source, an event is created by the input plugin. This event can then be processed by other directives. Events consist of three elements: tag, time, and record:

The event tag allows other directives to select the event for processing. Tags are period-delimited strings. Filter and match directives are the main consumers of tagged events.
Time is a unix time string inserted by the input plugin upon event generation. Note that this records the time Fluentd received the data, not the time it was originally created. For example, an application running in a Kubernetes cluster might emit a log message to a Kafka cluster which might then make its way to Fluentd several seconds after it was originally created.
The Fluentd event record is a JSON object that contains the actual information inside the event. The record is what is processed by filters and ultimately sent to the output plugins. This is essentially the “application” level traffic flowing through Fluentd.
The example below shows two Fluentd source directives:

The first directive tells Fluentd to create events from HTTP requests received on port 24220 with the in_http input plugin.
The second directive uses the in_tail input plugin to create events from a file at /var/nginx/log. The source directive also extracts data like the user agent or response code from each log line and adds the data as keys to the event using the NGINX parser plugin. Finally, all events generated by the second source directive are given the @nginx label.
<source>
  @type http
  port 24220
</source>

<source>
  @type tail
  path /var/nginx/log
  <parse>
    @type nginx
  </parse>
  @label @nginx
</source>

Match Directives
Each match directive opens with a <match pattern> and ends with </match>. The pattern corresponds to the tag of incoming events that will be processed by the match directive’s output plugin.

Please consider the following example:

<match app>
  @type stdout
  <format>
    @type msgpack
  </format>
</match>

<label @nginx>
...

  <match *nginx.*>
    @type mongo
    # ... mongodb plugin args
      ...
    <buffer>
      @type file
      path tmp/buffer/nginx.log
    </buffer>
  </match>
</label>

The pattern can be a literal, such as example.app, or a wildcard expression matching various tags, such as app.*. A few things to remember:

* matches a single tag part.
** matches zero or more tag parts.
{} defines a set of possible matching patterns.
Tag parts are delimited with "."

app.* would match app.web but not app or app.api.client
app.** would match app, app.web and app.api.client
app.{web,api}.** would match app.web and app.api.client but not app
The @type parameter is required and determines the output plugin to use. 

Match directives are evaluated in the order as listed in the configuration file. Matched events are removed from the stream and are not available to follow-on match directives. For example, if the first match pattern matches all of the events, then follow-on match directives will have no events to process.


Filter Directives
Filter directives provide much of the processing portion of a Fluentd data pipeline. They allow events to be dropped, enriched and/or transformed before they are sent to match directive output plugins. Like match directives, filter directives perform processing on events with tags matching the filter’s pattern.

Please consider the following example:

<filter app>
  @type grep
  regexp1 message POST
</filter>
<filter app.web>
  @type record_transformer
  <record>
     hostname "#{Socket.gethostname}"
  </record>
</filter>

Some useful cases for filter directives include:

Filtering out events that do not need to be forwarded.
Enriching data by adding new fields.
Transforming data by changing fields and/or reformatting data.
Deleting or obfuscating fields for privacy and/or compliance purposes.
If a filter directive uses the same pattern as a match directive, it should be placed before the match in the configuration file. Otherwise, the match directive will be evaluated before the filter can perform its intended function.

Fluentd comes with three built-in filter plugins:

grep – removes events that do not match the grep pattern.
record_transformer – adds or modifies event message fields.
filter_stdout – prints matching events to stdout (typically for debugging).

Labels
Label directives are used to create a configuration file within a configuration file. Labels collect filter and match directives into a processing pipeline which can be invoked by any source directive. Directives nested under a label follow the same syntax as top level directives. Events routed to label directives retain their tags as assigned by the input plugin, so the filter and match directives can perform processing and delivery based on their tag patterns.

Source directives support the @label parameter:

Directs events to a specific processing pipeline.
Makes complex configuration files easier to manage.
Allows parallel processing pipelines to be represented in a single file without tag conflicts.
Label directives contain other directives much like the top level of a normal configuration file:

Label directives can nest filter and match directives.
Source event tags can be used to match patterns within the label’s processing logic.
Please consider the following example:

<source>
  @type tail
  path /var/nginx/log
  @label @nginx  
</source>

<label @nginx>
  <filter>
   @type stdout
 </filter>
 <match *nginx.*>
   @type mongo
   # ... mongodb plugin args
     ...
 </match>
</label>

Labels can be changed or assigned in match directives by using the out_relabel plugin. This is useful when organizing complex data processing workflows and allows multiple labels to be connected together.

Label directives are given names beginning with an @.

Common Subdirectives
There are five subdirectives/plugin types:

<parse> - Parser
<format> - Formatter
<buffer> - Buffer
<storage> - Storage
<service_discovery> - Service discovery
These plugin types are invoked within other directives. Multiple nested directives can be utilized. A given directive plugin may support all, some or no subdirective types. The plugin documentation for a given plugin will specify which subdirectives are supported. For example, the forward input plugin cannot use the <parse> subdirective type.

Please consider the following example:

<source>
  @type tail
  path /var/nginx/log
  <parse>
    @type nginx
  </parse>
  @label @nginx  
</source>

<match app>
  @type stdout
  <format>
    @type msgpack
  </format>
</match>

<label @nginx>
  <filter>
   @type stdout
  </filter>
  <match *nginx.*>
    ...
    <buffer>
      @type file
      path tmp/buffer/nginx.log
    </buffer>
  </match>
</label>

Parser plugin is nested in source, filter and match directives with the <parse> tag. It typically allows inbound events to be broken down into a standard set of fields for further processing. For example, an nginx log line can be organized into a JSON document by the nginx parser, with JSON fields for the date and time, the route, verb and so on. Because the JSON format is supported by many Fluentd plugins, parsing inbound events into JSON is a common Fluentd task.

Formatter plugins are nested under filter and match directives with the <format> tag. They are used by filter and output plugins to place messages into an appropriate output format for the target system. Formatter plugins can convert messages from JSON to message pack, CSV, tab separated, etc.

Buffer plugins are used exclusively match directives with the <buffer> tag, specifying buffer file locations, size and time limits. Please note that Fluentd typically buffers events into batches for delivery efficiency.

Storage plugins are not widely used; however, in certain settings they can be valuable because they allow the outer directive’s plugin to define a custom internal storage scheme for events. Some of the third party storage plugins include:

fluent-plugin-storage-leveldb
fluent-plugin-storage-memcached
fluent-plugin-storage-mongo
fluent-plugin-storage-redis
Service discovery plugins are also used exclusively in match directive. They allow output targets to be defined outside of the Fluentd configuration file using an external file or through DNS SRV records. This allows output targets to be defined independently from processing logic.

Advanced Sections
The less frequently used advanced sections are implemented through plugin helpers, rather than standalone plugins. Like other subdirectives, not all plugins can make use of them.

Click on each box to learn about the three advanced subdirectives.

Advanced Subdirectives
Close Inject
This section allows values to be inserted into records, and is nested under filter and match directives with the <inject> tag. Inject sections allow values to be inserted into records which can be useful for debugging, development and general logging purposes.

Close Extract
This section allows values to be extracted from a record. Extract sections are nested under source, filter and match directives with the <extract> tag. Of the core plugins, only in_exec, in_tcp, in_udp and out_exec support this section.

Close Transport
This section is nested under source, filter and match directives with the <transport> tag. It is used to configure the transport protocol for events, including enabling TLS and assigning certificates.

Please consider the following example:

<inject>
  time_key example_time
  time_type string
  time_format %Y-%m-%dT%H:%M:%S.%NZ
  tag_key example_tag
</inject>

# If the record looks like:
tag: record-tag
time: 1547575563.952259
record: {"message":"example msg"}

# The record w/ the inject is:
{"message":"example msg", "example_tag":"record-tag", "example_time":"2019-01-15T18:06:03.952259000Z"}




System Directives
Many system-level Fluentd configurations can be placed inside the configuration file. And many of these configurations mirror command line arguments supported by Fluentd.

The following settings can be placed in a system directive in the configuration file:

emit_error_log_interval determines the error log write frequency.
log_level sets the logging verbosity of the Fluentd instance, equivalent to the -q(q) or -v(v) command line arguments. Some plugins support this setting directly, allowing it to be overridden within the directive that includes the plugin.
-v = debug
-vv = trace
-q = warn
-qq = error
process_name can be used to changed the name of the Fluentd instance according to the OS. This can be useful if running more than one Fluentd instance on the same machine (such as a log forwarder and an aggregator).
suppress_repeated_stacktrace is used to prevent errors from flooding logs with identical stack traces. Multiple instances of stack traces will be replaced with “suppressed same stack trace” until another message is generated. Since v0.12, this option is true by default.
suppress_config_dump prevents configuration details from being dumped to a terminal or log at startup, which is useful for protecting potentially sensitive information that may exist inside the configuration file.
without_source starts Fluentd without input plugins by ignoring the <source> tags in the configuration file, which can be used to allow Fluentd to flush any latent disk buffers without accepting new inputs.
NOTE: This list is not exhaustive, and a complete and up-to-date version is always available in the Fluentd Documentation.

Please consider the following example:

<system>
  emit_error_log_interval 60         # equal to --emit-error-log-interval flag
  log_level error                    # equal to -qq
  process_name myfluentd
  suppress_repeated_stacktrace false # equal to --suppress-repeated-stacktrace flag
  suppress_config_dump               # equal to --suppress-config-dump
  without_source                     # equal to --without-source flag
</system>

Full Configuration File
Now that we have explored the various directives and subdirectives supported by Fluentd, let’s take a look at a typical complete configuration file.

<source>
  @type http
  port 24220
</source>

<source>
  @type tail
  path /var/nginx/log
  <parse>
    @type nginx
  </parse>
  @label @nginx  
</source>

<filter app>
  @type record_transformer
  <record>
    message Fluentd logged ${record[“message"]}
  </record>
</filter>

<match app>
  @type stdout
  <format>
    @type msgpack
  </format>
</match>

<label @nginx>
  <filter>
   @type stdout
  </filter>
  <match *nginx.*>
    @type mongo
    # ... mongodb plugin args
      ...
    <buffer>
      @type file
      path /tmp/buffer/nginx.log
    </buffer>
  </match>
</label>

Two sources

The first source directive uses the in_http plugin to enable Fluentd to accept messages posted over http on port 24220.
The second source directive uses the in_tail plugin, which reads from a file defined by the path parameter. A parser plugin, parser_nginx, is used to parse the nginx file format into JSON. The second source is bound to the @nginx label directive, sending all events from this source to the <label @nginx> pipeline.
Filter directive
A filter directive follows the source directives in this configuration file. This filter will only apply to http events with the app tag. Events from the tail source are prebound to the @nginx label and will not be considered. The filter will process events using the record_transformer plugin, adding the "Fluentd logged" text to the event. Filter directives will be covered in Chapter 5 of this course: "Filtering Data and Creating Pipelines".

Match directive
The filter directive is followed by a match directive. This match directive will apply to events tagged "app". It will use the out_stdout output plugin to send events to stdout. A format plugin, msgpack, will format the message data in msgpack format. This completes the processing pipeline for the first source directive.

Label
The final directive in the configuration is the label. This label will receive events from the tail source. Under this label are a filter and match directive. The filter will print all events to stdout. The match directive will buffer events tagged *nginx.* to a disk buffer before sending them in batches to a MongoDB instance. Label directives change the buffer behavior to save all unsent data to a file at /tmp/buffer/nginx.log.


Setting the Fluentd Configuration File
A Fluentd instance can be configured in several ways, in order of increasing priority.

A default path which varies with installation method and distribution. These installation schemes provide default configuration files which can be edited or deleted. For example, Ruby Gem and source installations search for /etc/fluent/fluent.conf. The Fluentd FLUENT_CONF environment variable takes precedence over default settings and the Fluentd --config command line flag overrides all other config file settings. For containerized instances of Fluentd, setting the FLUENT_CONF environment variable is the easiest way to set the configuration file. If no configuration file is provided Fluentd will not start.

For td-agent installations, Fluentd uses /etc/td-agent/td-agent.conf as the default and for Ruby Gem and source installations Fluentd uses /etc/fluent/fluent.conf.

Basic configuration examples for a variety of common applications are located in the Fluentd GitHub repository.

Please consider the following example:

user@ubuntu:~$ fluentd

/var/lib/gems/2.3.0/gems/fluentd-1.3.3/lib/fluent/supervisor.rb:760:in `initialize': No such file or directory @ rb_sysopen - /etc/fluent/fluent.conf (Errno::ENOENT)

user@ubuntu:~$ fluentd --config ./fluent/fluent.conf

2019-02-04 11:01:39 -0800 [info]: fluent/log.rb:322:info: parsing config file is succeeded path="./fluent/fluent.conf"

user@ubuntu:~$ export FLUENT_CONF=~/fluent/fluent.conf

user@ubuntu:~$ fluentd

2019-02-04 11:02:19 -0800 [info]: parsing config file is succeeded path="/home/user/fluent/fluent.conf"

Chapter Overview
In the previous chapter, you were introduced to configuration files and directives.

In the next few chapters, we will cover the software components that enable directives: plugins. This chapter will examine the most important built-in Fluentd plugins. We will see how plugins interact and combine to perform complex tasks in pipelines. We will also take a look at the large Fluentd third party plugin ecosystem.

Learning Objectives
By the end of this chapter, you should be able to:

Understand Fluentd's pluggable architecture.
List Fluentd's core plugins.
Examine how plugins expand Fluentd’s capabilities.
Identify the benefits plugins bring to Fluentd.
Explore the plugin ecosystem of Fluentd.
Learn how to install third party Fluentd plugins.


Plugins
To operate as a Unified Logging Layer Fluentd must be able to easily interact with all common log sources and targets. Fluentd plugins make it easy for third parties to extend Fluentd in a modular way. New plugins for input and output components that have yet to be invented can be constructed at any time, immediately empowering Fluentd to interoperate with those new components. Fluentd is essentially a plugin framework and all of the practical functionality within Fluentd is provided by plugins. In the Chapter 2 labs, we saw that Fluentd has no functionality until plugins are added to the configuration.

Basic data processing functionality is provided by Fluentd core plugins—a set of plugins that are included with normal Fluentd installations. These core plugins give Fluentd all of the basic functionality required to interact with the most common input and output targets (an input plugin consumes log data and an output plugin forwards that data to some target database, filesystem or other destination), as well as fairly robust parsing and filtering functionality. Core plugins can be combined into a processing pipeline, allowing a wide range of log processing solutions to be created. While you can almost always solve any problem with a processing pipeline created with core plugins, complex processing may require long, hard to read combinations of plugin configuration stanzas. Such complex pipelines using the core plugins may also require deep knowledge about how a given log prints its data or how to make the correct API calls against an application to retrieve event data.

Application-specific Fluentd plugins, custom-developed or sourced from the community, can provide users with a much simpler and richer solution. Plugins that do not ship with Fluentd are considered third-party, even if they are made by core contributors to the Fluentd project. Third-party plugins can allow Fluentd to work efficiently with new applications and can also give Fluentd additional capabilities for testing, debugging and other uses. For example, a wide range of output plugins are available, supporting almost every common database and queueing platform. Fluentd plugins are generally written in Ruby and are easily distributable through the Ruby Gems ecosystem.

The diagram shows how a hypothetical MQTT sensor might output data to Fluentd via an MQTT input plugin. The Fluentd instance then sends that data to MongoDB via an output plugin.

Directives and Plugins
This diagram illustrates how plugins fit into the directives of a Fluentd processing pipeline. Each section represents a directive as configured in a Fluentd configuration file. To the left is a source directive, in the middle, the filter directive, and on the right a match directive.

 

How plugins fit into the directives of a Fluentd processing pipeline
 

Click on each box to learn more about these three directives.

Directives
Close Source Directive
In the source directive, a data source sends or is scraped for event data. This is performed by an input plugin, which either listens, requests or tails for event streams that it is configured to retrieve. Input plugins can be augmented with parser plugins, which allow Fluentd users to state what sort of input or format an incoming data stream will arrive in.

Once an event is ingested by the source directive and given a tag and timestamp, the Fluentd routing engine uses the tag to route the message to the next appropriate directive.

Close Match Directive
Match directives use output plugins, which can be supported by buffer and format plugins to ensure that outgoing data are sent to their destinations.

Close Filter Directive
Filter directives can be placed between source and match directives to process events in some way before outputting them. Filters can also ingest data from, and output data to, other filters. Because filters read in data, they can use parser plugins (normally used in source directives) and because they emit data, they can use format plugins (normally used in match directives). Choosing whether to parse in the source or filter directive is a matter of application specific design. For example, an application with two different inputs, each with their own formats, sharing a single filter would probably be best advised to place parsers in the source directive so that each source could define its own parser. On the other hand, a similar application with two inputs that share the same format, might be better designed with a single parser configured in a shared filter directive.

Storage plugins (beneath each of the directives in the diagram) can be used in every directive type to capture the output of the directive. This can be helpful, for example, when one needs to tee off data in the middle of a pipeline for target system A, and yet continue processing the data before outputting it to target system B, or when capturing log data at the host level before output plugins forward it to an aggregated storage backend.



Plugin Types
Fluentd supports eigh different plugin types:

Input plugins
Output plugins
Filter plugins
Parser plugins
Formatter plugins
Buffer plugins
Storage plugins
Service discovery.
We will examine each in turn.



Source Directive Plugin Types
Input plugins enable Fluentd to consume events from a variety of source systems, turning Fluentd into a flexible data aggregator. Input plugins can read files within an application’s filesystem, receiving data from applications via TCP, or even scrape data from an application endpoint at a scheduled frequency.

Input plugins can be helped by parser plugins, which interpret and reformat incoming data. For example, the apache2 parser plugin takes normal Apache web server log data, which looks like this:

192.168.0.1 - - [28/Feb/2013:12:00:00 +0900] "GET / HTTP/1.1" 200 777 "-" "Opera/12.0«

…and turns it into well-formatted JSON that looks like this:

{ "user" : nil, "method" : "GET", "code" : 200, "size" : 777, "host" : "192.168.0.1", "path" : "/", "referer": nil, "agent" : "Opera/12.0" }

The JSON data can be more easily and generically searched and filtered than the raw web log data. The apache2 parser also extracts the timestamp from the log data and uses it as the Fluentd message timestamp (rather than arrival clock time).

If a user wishes to save parsed input for reuse later in the pipeline, the storage plugin type can be used to do so.

Core Input Plugins
The core input plugins enable Fluentd to receive a wide variety data streams including: TCP/UDP data, events from other Fluentd instances, data transmitted over Unix domain sockets, HTTP POSTs, file lines, syslog messages, among other options.

We distinguish different types of core input plugins:

in_dummy: Generates dummy events for testing and debugging.
in_exec: Executes external programs on a schedule to retrieve events.
in_forward: Listens to a TCP socket to receive an event stream from other Fluentd instances.
in_http: Receives records POSTed over HTTP.
in_syslog: Receives records via the syslog protocol.
in_tail: Reads events from the tail of text files.
in_tcp/in_udp: Receives TCP/UDP payloads.
in_unix: Retrieves records from a Unix domain socket.
in_windows_eventlog: Configures Fluentd to read events from the Windows Event Log.
NOTE: Core plugins are included with Fluentd and no additional installation is required.

The code block below shows three different <source> directives. The first uses the in_forward plugin, which enables Fluentd to receive event traffic from other Fluentd instances, in this case, on port 32767. The second directive uses the in_http plugin, which opens port 35000 to incoming HTTP traffic. The third directive uses in_tail, which will continually print events from the tail of the file defined by the path parameter.

<source>
  @type forward
  port 32767
</source>

<source>
  @type http
  port 35000
</source>

<source>
  @type tail
  path /tmp/app.log
  pos_file /tmp/app.log.pos
  tag some.tag
  <parse>
    @type none
  </parse>
</source>

Match Directive Plugin Types
Match directives support output, format, buffer and service discovery plugins.

Output plugins are used by match directives to distribute collected data/processed events to external destinations. They come in three distinct types: 

Non-buffered output plugins perform no buffering of the received data, and simply write out results to their intended destinations. Buffer plugins are not used with non-buffered output plugins.
Buffered plugins maintain a queue of collected events, or chunks, and send them out when an appropriate amount of data is collected. Buffer plugins can define specific buffering schemes (size/location) and mediums (disk/memory) to use.
Time sliced output plugins are a type of buffered plugin which emit chunks at timed intervals. Time sliced output plugins can also be configured using buffer plugins.
Format plugins reformat event data to suit the target destination (e.g., converting a JSON message into CSV format).

Buffer plugins are used by buffered output plugins to give users the ability to control buffering behavior in advanced ways. This can include indicating the tags a buffer is associated with, adjusting the size of buffered chunks and how often the chunks are flushed to the output queue.

Service discovery enables supported plugins to find destinations via service discovery.

Like other directives, match directives can save output using storage plugins.

Core Output Plugins
The core output plugins allow Fluentd to send data to multiple destinations simultaneously or in sequence, forward data to other Fluentd instances, execute programs, pass events to other programs, or output data to various destinations directly, such as files or cloud services.

We distinguish different types of core output plugins:

Non-buffered

out_copy: Copies events to multiple outputs.
out_null: Throws away events.
out_roundrobin: Distributes events to multiple outputs using a round-robin algorithm.
out_stdout: Prints events to stdout.
Buffered

out_exec_fliter: Executes an external program using an event as input and reads a new event from the program output.
out_forward: Forwards events to other Fluentd nodes.
out_mongo or out_mongo_replset: Writes records into MongoDB.
Time sliced

out_exec: Passes events to an external program.
out_file: Writes events to files.
out_s3: Writes records into the Amazon S3 object storage service.
out_webhdfs: Writes records into Hadoop Distributed File System (HDFS).
NOTE: Core plugins are included with Fluentd and no additional installation is required.

The example code block shows three match directives that are configured to use some of the output plugins described. The first directive uses the out_stdout plugin, which will send all Fluentd events to the Fluentd host's standard output unbuffered. The second match directive uses the out_forward plugin, which allows Fluentd to send events to another Fluentd instance buffered. The third directive shows the use of the copy output plugin, which is configured to send files to the cloud (Amazon S3) using the out_s3 plugin and to a local file, using the out_file plugin, at the same time using time sliced buffering.

<match my.tag>
  @type stdout
</match>

<match *.tag>
  @type forward
  <server>
    name aggregator1
    hostname 172.17.0.2
    port 32767
  </server>
</match>

<match **>
  @type copy
  <store>
    @type s3
    ...
  </store>
  <store>
    @type file
    path /tmp/local/all.logs
  </store>
</match>

Filter Directive Plugin Types
Filter plugins are used to modify fields or data as they pass through Fluentd’s processing pipeline. These are useful if data needs to be manipulated, for example, obfuscating a value for security purposes, modifying values to better suit the requirements of an intended destination, or to simply improve readability. This is done by allowing a user to determine what patterns need to be filtered, and how the filtered patterns need to be changed. Filter plugins modify event streams by:

Filtering events based on search criteria.
Enriching events by adding new fields.
Deleting or masking fields for privacy or compliance.
Filter directives are used between source and match directives, and as such can use both parser plugins on input and formatter plugins on output. Parse and format plugins are specified using the corresponding subdirectives: <parse> and <format>.

Output can be saved using a storage plugin.


Core Filter Plugins
The core filter plugins allow Fluentd to identify patterns to be filtered, transform data in user-defined ways, and print filtered events to stdout for debugging.

We distinguish different types of core filter plugins:

filter_grep: "Greps" events by the values of specified fields.
filter_parser: "Parses" string records into discrete fields.
filter_record_transformer: Transforms incoming event streams. It can mutate events, adding fields like the hostname or the result of an arbitrary Ruby expression.
filter_stdout: Prints events to stdout for debugging purposes.
filter_geoip: Adds geographic location information to events using the MaxMind GeoIP databases.
NOTE: Core plugins are included with Fluentd and no additional installation is required.

Multiple filter directives can be applied to events sequentially. In the example below, the first directive matches events with the tag my.tag, and if the “message” field’s value contains “example”, the event continues to be processed by follow on directives, otherwise it is removed from the processing pipeline.

<filter my.tag>
  @type grep
  regexp1 message example
</filter>

<filter my.tag>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
  </record>
</filter>

<filter some.tag>
  @type record_transformer
  enable_ruby
  <record>
    avg ${record["total"] / record["count"]}
  </record>
</filter>

Core Parser Plugins
The following table presents core parser plugins.

 

PLUGIN NAME	CONFIG FILE @TYPE	PURPOSE
parser_regexp	regexp	Parses incoming streams based using a user-defined regular expression.
parser_apache2	apache2	Predefined regular expression for parsing Apache web server access logs.
parser_apache_error	apache_errror	Predefined multi-line and regular expression settings for parsing Apache web server error logs.
parser_nginx	nginx	Predefined RegEx and time format for NGINX logs.
parser_syslog	syslog	Parses syslog-generated logs, supporting RFC-3164 and RFC-5424.
parser_ltsv	ltsv	Parses events from labeled, tab-separated value inputs.
parser_csv	csv	Parses events from comma-separated value inputs.
parser_tsv	tsv	Parses events from tab-separated value inputs.
parser_json	json	Parses events from JSON inputs.
parser_msgpack	msgpack	Parses events from msgpack inputs.
parser_multiline	multiline	Parses logs that print single events in multiple logs.
parser_none	none	Parses a log as is to defer the structuring to the incoming data stream.


Core Formatter Plugins
The following table presents core formatter plugins.

 

PLUGIN NAME	CONFIG FILE @TYPE	PURPOSE
formatter_out_file	out_file	Outputs the time, tag, and JSON with a chosen delimiter to a file.
formatter_json	json	Formats an event in JSON without a tag or time field (by default, this can be changed).
formatter_ltsv	ltsv	Formats an event in labeled, tab-separated value format.
formatter_csv	csv	Formats an event in comma-separated value format.
formatter_msgpack	msgpack	Converts an event into msgpack binary format.
formatter_hash	hash	Converts an event into Ruby hash format without a time or tag field.
formatter_single_value	single_value	Outputs only the value of a single field rather than a whole record.
formatter_tsv	tsv	Formats an event in tab-separated value format.


Core Buffer Plugins
The following table presents core buffer plugins.

 

PLUGIN NAME	CONFIG FILE @TYPE	PURPOSE
buf_memory	memory	Instructs the plugin to store its event buffer in memory for speed.
buf_file	file	Instructs the plugin to store its event buffer in a specified file for durability.
 

The core buffer plugins allow buffer chunks to be stored in memory for performance or on disk for persistence. Buffers stored in memory that cannot be written fast enough are discarded. For on disk buffering, it is important to maintain appropriate free disk space and also to ensure that remote file systems are not used.



Other Core Plugin Types
The remaining core plugins included with Fluentd cover plugin storage and service discovery.

 

PLUGIN NAME	CONFIG FILE @TYPE	PURPOSE
storage_local	local	Saves a plugin's internal state as key-value pairs to a local file.
sd_static	static	Allows users to declare service discovery endpoints directly in the configuration file under the supported plugin.
sd_file	file	Instructs the supported plugin to retrieve service discovery endpoints from a specified file.
sd_srv	srv	Instruct the supported plugin to retrieve the service discovery endpoints from the SRV records of a specified domain name.


Fluentd Plugin Ecosystem
Most of the plugins that are available for Fluentd were developed by the community and number in the hundreds due to the widespread use of Fluentd and the ease of creating plugins. Some third party plugin features can be replicated by configuring a series of core plugins; however, third party plugins are often created to simplify tasks that are complex and/or error prone when using core plugins.

Plugins that were developed by Fluentd core committers or contributors that have made commercial commitments to Fluentd are marked as Certified. The certification program is meant to inform potential users that a plugin is ready for production use.

Click on each box to learn about selected certified plugins.

Certified Plugins
Close Amazon Web Services (AWS)
kinesis: Output plugin that sends events to Amazon Kinesis.
S3: Amazon S3 output plugin for Fluentd.
Close Big Data
td: Treasure Data Cloud Data Service output plugin for Fluentd.
webhdfs: For WebHDFS and HttpFs output plugin for Hadoop FileSystem.
Close Filter
anonymizer: Anonymizes records with HMAC of MD5/SHA1/SHA256/SHA384/SHA512 algorithms; protects privacy for UserID, email, phone number, IPv4/IPv6 address.
filter_typecast: Casts record types.
grok-parser: Supports Logstash-inspired Grok format for parsing.
multi-format-parser: Multi-format parser plugin.
record-modifier: Plugin for modifying event records.
record-reformer: Adds or replaces fields of an event record.
rewrite-tag-filter: Designed to rewrite tags when a value matches a regular expression.
woothee: Parsing by Project Woothee; multi-language user-agent string parsers.
Close Monitoring
growthforecast: Output plugin for GrowthForecast, a web tool that lets you graph all sorts of metrics via a WebAPI.
ping-message: Input and output plugin for heartbeat monitoring of Fluentd processes.
Close Notifications
ikachan: Output plugin for IRC-HTTP gateway 'ikachan'.
twilio: Output plugin to make a call with Twilio VoIP API; Twiml supports text-to-speech with many languages.
Close NoSQL
influxdb: Output plugin for sending data to InfluxDB.
mongo: Output plugin for sending data to MongoDB.
Close Online Processing
norikra: Processes events with SQL-like queries, with built-in Norikra server if needed; input, output and filter plugins.
Close RDBMS
mysql: Output plugin to insert MySQL as JSON (single column) or insert statement.
mysql-replicator: Input and output plugin to track insert/update/delete events from MySQL; can generate nested documents for ElasticSearch/Solr.​​​​​​​
Close Search
elasticsearch: Output plugin for Fluentd event collector.
To see the entire list review Fluentd's "List of Plugins by Category".



Using Plugins
Plugins are loaded by Fluentd at initialization. The @type argument in directives specifies the plugins to load. Fluentd plugins are written in Ruby and distributed as Ruby gems. The fluent-gem tool, a Fluentd-specific wrapper for the Ruby gem command, can be used to download plugins available in the official Fluentd plugin registry. Ruby Gemfiles can be used to load and maintain specific plugin versions for Fluentd instances, allowing for stable and predictable configurations. Finally, plugins defined by raw Ruby scripts in .rb format can be placed into any plugin directory that Fluentd recognizes.

Once installed, Fluentd will only load a plugin if it is called in a directive’s @type argument.

Compatibility:

Fluentd v1 is the current major release of Fluentd, supporting Fluentd plugin API 1.0+.
Fluentd v0.14 became Fluentd 1.0 (and thus plugins are interchangeable version-wise).
Fluentd 0.13 was a development version and should not be used in production.
Fluentd v0.12 plugins can be used by Fluentd 1.0+ via a compatibility wrapper (backwards compatibility will be deprecated as of Fluentd v2.0).
The configuration example here demonstrates a config that uses the http input plugin, record_transformer filter plugin, and the stdout output plugin supported by the msgpack format plugin. No other plugins will be loaded by this configuration.

<source>
  @type http
  port 24220
</source>

<filter app>
  @type record_transformer
  <record>
    message Logged ${record[“message"]}
  </record>
</filter>

<match app>
  @type stdout
  <format>
    @type msgpack
  </format>
</match>
Installing Plugins with fluent-gem
fluent-gem is a wrapper for the Ruby gem command and is functionally identical to the standard Ruby gem command. Some plugin documentation may refer to either the gem or fluent-gem commands to install plugins. Installing plugins this way will ensure that all Ruby dependencies for a given plugin are met. 

Gem installations will usually install the latest available plugin. While this is excellent for ensuring that all plugins are up-to-date, there are cases where it may be preferable to load a specific version of a plugin. This is especially important for users that are still using Fluentd version 0.12, as those plugins have a hard dependency on 0.12 and the old plugin API that was replaced in version 0.14 (and later, version 1.0).

In production, using fixed plugin versions is recommended:

$ fluent-gem install fluent-plugin-nginx-error-multiline

Fetching: fluent-plugin-nginx-error-multiline-0.2.0.gem (100%)
Successfully installed fluent-plugin-nginx-error-multiline-0.2.0
Parsing documentation for fluent-plugin-nginx-error-multiline-0.2.0
Installing ri documentation for fluent-plugin-nginx-error-multiline-0.2.0
Done installing documentation for fluent-plugin-nginx-error-multiline after 0 seconds
1 gem installed




Managing Plugins with Gemfiles
Fluentd can utilize Ruby Gemfiles to configure the plugin ecosystem for individual instances. These files contain a list of gems that need to be installed in order to enable Fluentd to function for that instance. Specific Fluentd versions can be declared inside the Gemfile, so a Gemfile can be used to install and run a different Fluentd version than the system version for stability or to fulfill other requirements. Note that attempting to run previous releases of Fluentd may not work, depending on the plugins to be loaded in the configuration file.

The Gemfile system utilizes Bundler to fulfill the installation of the listed gems; in order to utilize a Gemfile, the bundler gem must be installed in the system. Depending on the installation method, users may need to use gem to install bundler before attempting to use Gemfiles. When running a Gemfile, a lock file is created that details all of the dependencies that were installed by the most recent Gemfile.

Fluentd instances using a Gemfile will install and load only the versions of the plugins that are declared inside the Gemfile. If a plugin is called inside a directive, and is not included in the Gemfile, it will attempt to look in any configured plugin directories (such as /etc/fluent/plugin or any directory passed with -p) when that instance is loaded. If Fluentd cannot find a plugin that is declared inside a configuration file, it will not start.

The use of Ruby Gemfiles relieves the user of the burden of managing dependencies. Bundler will automatically detect and fulfill the dependencies, and through the use of a lock file, will show exactly what plugins and their versions were required to successfully run a given instance of Fluentd. The downside (shared with the fluent-gem command) is that Gemfile processing requires an Internet connection and access to the outside world—something some users (particularly enterprises and heavily secured environments) may not have access to.

~/fluent/Gemfile

source 'ht‌tps://rubygems.org'

gem 'fluentd', '1.3.2'
gem 'fluent-plugin-mongo', '1.9.3'
gem 'fluent-plugin-webhdfs', '1.2.3'

Manually Installing Fluentd Plugins
The final way to install Fluentd plugins is manually. This involves configuring raw Ruby scripts (with .rb file extensions). All code associated with a Fluentd plugin must be configured by the user. This is useful in settings with limited access to the outside world or those that require in-house compiling and test for all deployments.

To install a plugin manually, the Fluentd plugin Ruby script must be placed inside a configured plugin directory. By default, gem installations of Fluentd will install to /etc/fluent/plugin. Plugins saved here do not require Fluentd to run with elevated privileges. Additional directories can be declared using the -p argument when launching Fluentd from the command line. As long as the plugin script is well-formed and is present inside a Fluentd plugin directory, any configurations that call the plugin will work.

/etc/fluent/plugin$ sudo wget htt‌ps://raw.githubusercontent.com/tagomoris/fluent-plugin-ping-message/master/lib/fluent/plugin/in_ping_message.rb

...
2021-05-04 16:12:32 (226 MB/s) - ‘in_ping_message.rb’ saved [842/842]

/etc/fluent/plugin$ ls -l

total 4
-rw-r--r-- 1 root root 842 May 04 16:12 in_ping_message.rb

Chapter Summary
The Fluentd plugin ecosystem is vast, offering many official and community-supported plugins.

Fluentd can be made to work with any combination of applications by using plugins.

Third party plugins allow complex pipelines consisting of multiple core plugins to be condensed into a single plugin.

Application-specific plugins enable Fluentd users to configure logging pipelines without full knowledge of all end- and intermediate points.

Chapter Overview
The previous chapter and lab provided a detailed introduction to Fluentd plugins and hands-on guidance on how to install and manage them.

This chapter will cover filter plugins in more detail. Fluentd’s core filter plugins have the ability to transform and change events as they are processed to best fit their intended destination.

You will be shown working examples of filter directives in action, and given an in-depth look at the power of Fluentd's event processing filter plugins.

Cases for Fluentd Log Processing
One of Fluentd’s strengths is its ability to combine logs and data from a variety of sources. However, not all sources and destinations make use of the same data format. By passing data and logs through Fluentd, format differences can be reconciled using the many Fluentd plugins. Both output and filter plugins can be useful in this regard.

For example, some application-specific runtime logs may have too much information or redundant data, making it expensive to store and process. A filter plugin, such as grep, can be used to filter any unneeded events.

Some data analysis tools require specific metadata with each event in order to effectively catalog and index the data. Fluentd can enrich records of incoming data by inserting metadata and other user-defined key-value pairs. For example, Fluentd can add timestamps, host information, container IDs, etc. Fluentd can also normalize logs from a wide variety of sources.

 

Illustration of two sources, one using proprietary log format and another using plaintext
 

The example above shows two sources: one that logs events in a proprietary log format using timestamps in 24-hour Month, Day, short year format and another that stores events in plaintext with a MMDDYY date and a 12-hour time format. Events coming from both of these sources can be standardized by Fluentd to meet the needs of a log database that records events in JSON with MM/DD/YY dates and Unix formatted timestamps.


Filter Directive
Fluentd uses filter directives to remove unwanted messages from a stream, though filters can also perform other data processing tasks. These directives are configured between a source and match directive. Fluentd configurations process directives in the order they are listed in the configuration file.

Filter directives are enclosed within a <filter> element. The top filter tag contains a pattern attribute defining the events the filter will be applied to, similar to match directives. The @type parameter in a filter can specify any filter_* prefixed plugin. As with all directives, the filter parameters depend on the plugin in use.

If the selected plugin supports it, <format> and/or <parse> directives can be utilized as subdirectives in a filter directive.

The following example shows a filter directive selecting all events (**). This directive is using the grep plugin. The filter directive will output only events with the event key set to actual.

$ cat fluentd.conf

<source>
  @type forward
</source>
 <filter **>
    @type grep
    <regexp>
      key "event"
      pattern /actual/
    </regexp>
  </filter>
<match>
  @type stdout
</match>

$ echo '{"event":"actual","data":"valid"}' | fluent-cat record ; echo '{"event":"test","data":"valid"}' | fluent-cat record

2021-05-04 16:45:33.842902363 -0700 record: {"event":"actual","data":"valid"}

filter_record_transformer
The filter_record_transformer plugin is one of the most popular filter plugins for modifying event data when it needs to be enriched, obfuscated, trimmed, or transformed. A Fluentd event consists of three basic elements: 

Tag 
Time 
Record
The record_transformer changes the record portion of an event. When record data is in JSON format, the record_transformer plugin allows key-value pairs to be added, modified or deleted in the record.

By using Ruby expressions, the functionality of filter_record_transformer can be expanded:

Data about the event itself, such as the tag and time, can be added to the record.
Certain system variables from the Fluentd host can be added.
Character substitution for obfuscation or standardization purposes can be applied.
Mathematical evaluation can be performed between two numerical values in an event.
The example shows the record_transformer filter plugin configured to append a new key (status) with the value (filtered) to all events.

$ cat fluentd.conf

<source>
  @type forward
  port 24224
</source>

<filter **>
  @type record_transformer
    <record>
      status filtered
    </record>
</filter>

<match>
  @type stdout
</match>

$ echo '{"event":"outcome"}' | fluent-cat record

2021-05-04 16:46:22.575081422 -0700 record: {"event":"outcome","status":"filtered"}

filter_record_transformer Parameters
When using filter_record_transformer, each key-value pair declared inside the <record> directive will be created or updated in the event’s record.

Existing record values can be updated, replaced or used to generate new fields. Given the record, {"msg":"foo", "number":10}, the value 10 could be accessed like this: record["number"].

Record components can be parameterized using curly braces {}. $ prefixed braces are replaced with the value of the enclosed variable. # prefixed braces are replaced with the output of the enclosed Ruby code.

Tags can also be referenced using tag_parts, tag_prefix, and tag_suffix. Fluentd expects tags to be segmented with each segment separated by a dot ("."). Segment indices are zero-based, so given the tag first.second.third, tag_prefix[0] would produce first.

tag_parts[N] refers to the Nth dotted part of the tag
tag_prefix[N] refers to the [0..N] part of the tag
tag_suffix[N] refers to the [N..] part of the tag.
Let's consider the following tag: first.second.third:

tag_prefix[0] = first  
tag_suffix[0] = first.second.third
tag_prefix[1] = first.second   
tag_suffix[1] = second.third
tag_prefix[2] = first.second.third   
tag_suffix[2] = third
The enable_ruby option, allows the result of an arbitrary Ruby expression to be used inside a parameter block (${ ... }).

The example uses the filter_record_transformer plugin on events having the tag my.tag. The msg key has its value appended with the word world, and the hostname key is added with the value of the Fluentd instance's host.

# If the unaltered record is:

{"msg":"hello"}

# and the filter is:

<filter my.tag>
  @type record_transformer
  <record>
    msg ${record["msg"]} world
    hostname "#{Socket.gethostname}"
  </record>
</filter>

# The resulting record will be:

{"msg":"hello world", "hostname":"host.example.com"}

filter_record_transformer:auto_typecast
auto_typecast enables automatic field type casting for generated values. The setting is enabled (true) by default. When enabled, any values generated by the filter_record_transformer plugin will be stored as numbers if the expression generating the value results in a number. Otherwise the string type is used. In the example below, the output of a calculated average between a total and a count is an integer; however, with auto_typecast set to false, the result is saved as a string.

Setting auto_typecast to false can be useful if an intended destination has issues with non-string values.

$ echo '{"total":50,"count":50}' | fluent-cat mod4

2021-05-04 16:47:00.944042970 -0700 mod4: {"total":50,"count":50,"avg":1}

$ cat fluentd.conf

...
<filter mod4**>
  @type record_transformer
  enable_ruby true
  <record>
    avg ${record["total"] / record["count"]}
  </record>
  auto_typecast false
</filter>
...

$ echo '{"total":50,"count":50}' | fluent-cat mod4

2021-05-04 16:47:38.46683241 -0700 mod4: {"total":50,"count":50,"avg":"1"}

filter_record_transformer:renew_record
filter_record_transformer provides the renew_record parameter which, when set to true, creates a new empty record that replaces the original record. This is useful when none or few of the original record fields need to be forwarded.

The keep_keys parameter can be supplied with the names of keys (separated by commas) to transfer from the original record to the new record. The <record> subdirective can also be used as usual to create new fields in the new record. The record[] array can be used to access values from the original record when composing fields in the new record.

$ cat fluentd.conf

<filter mod4**>
  @type record_transformer
  enable_ruby
  <record>
    action ${record["log"]}
  </record>
  renew_record true
  keep_keys weather
</filter>

$ echo '{"time":"today","weather":"rain","log":"stayed inside"}' | fluent-cat mod4

2021-05-04 16:48:13.373587612 -0700 mod4: {"weather":"rain","action":"stayed inside"}

filter_record_transformer:renew_time_key
The filter_record_transformer renew_time_key parameter overwrites the message timestamp with the value of a named record field. The time value must be in Unix time format.

NOTE: It cannot be used in the same directive as renew_record.

In the example below, the event: real key-value pair record is passed to Fluentd and given a timestamp of 16:49:18.677062634 by Fluentd on receipt. The second example demonstrates the use of the renew_time_key parameter, setting the timestamp to the value of the timetag key (150). In this case, Fluentd sets the timestamp of the event to 150 seconds after the Unix time epoch, January 1st, 1970 at 0:00 UTC. After factoring in the local time zone (in this case, UTC-8), the event is published with the timestamp 1969-12-31 16:02:30.000000000, which is December 31st 16:00 plus 150 seconds.

$ echo '{"event":"real"}' | fluent-cat mod4

2021-05-04 16:49:18.677062634 -0700 mod4: {"event":"real","reality":"real"}
...
<filter mod4**>
  @type record_transformer
  enable_ruby
  <record>
    reality ${record["event"]}
  </record>
  renew_time_key timetag
</filter>
...

$ echo '{"event":"real","timetag":"150"}' | fluent-cat mod4

1969-12-31 16:02:30.000000000 -0800 mod4:
{"event":"real","timetag":"150","reality":"real"}

filter_record_transformer:remove_keys
As records are transformed and have information added to them, some keys may become redundant or they may need to be removed for obfuscation. In the example, the filter_record_transformer remove_keys parameter allows named keys (username) to be removed from the output record.

$ cat fluentd.conf

...
<filter **>
  @type record_transformer
  enable_ruby
  <record>
    message login - ${record["username"]}
  </record>
  remove_keys username
</filter>
...

$ echo '{"username":"student"}' | fluent-cat event

2021-05-04 16:51:18.257313920 -0800 event: {"message":"login - student"}

filter_grep
The filter_grep plugin functions similarly to the standard Linux grep tool, forwarding events that match a user-defined pattern. It filters out events using regular expressions (regexp).

The grep filter directive is configured using subdirectives:

<regexp> - forwards events that match the regexp pattern.
<exclude> - drops events that match the regexp pattern.
Both <regexp> and <exclude> use the "key" and "pattern" parameters. The <regexp> subdirective defines a field (key) and a regular expression (pattern) to match. Records having a value for the given key matching the given pattern are forwarded; other records are dropped. The <exclude> subdirective performs the opposite task, dropping records that do match.

Please consider the following example:

<filter my.tag>
  @type grep
  <regexp>
    key message
    pattern /string-literal/
  </regexp>
  <regexp>
    key hostname
    pattern /^db\d+\.example\.com$/
  </regexp>
  <exclude>
    key message
    pattern /other-string/
  </exclude>
</filter>

By default, all subdirectives must be satisfied (logical AND) to forward the record. The <and> and <or> subdirectives can be used to change this logic:

<and> - All regexp and exclude patterns must be satisfied.
<or> - Only one of the enclosed patterns needs be satisfied.
For example, you could place regexp A and B in an <or> block to allow records matching either A or B to be forwarded.

filter_parser
The filter_parser plugin parses a given key’s string value, replacing the top level fields in the record with the parsed fields from the string:

key_name – the name of the record to parse.
<parse> – the parser to use (JSON, CSV, msgpack, TSV, nginx, apache2, etc.). 
Original record data can be preserved with reserve_* parameters:

reserve_time – keeps the original timestamp (otherwise current time is used).
reserve_data – keeps the original record data (appending parsed key-value data).
remove_key_name_field – removes the parsed key-value data from the record.
Take a look at the following example:

# If the unaltered record is:

{"key":"value","user":"{\"foo\":1,\"bar\":2}"}

# and the filter is:

<filter my.tag>
  @type parser
  key_name user
  reserve_data true
  remove_key_name_field true
  <parse>
    @type json
  </parse>
</filter>

# The resulting record will be:

{"key":"value","foo":1,"bar":2}

Additional options include:

replace_invalid_sequence – replaces a string with safe characters and re-parse the string.
inject_key_prefix – adds a specified prefix to the keys in a record.
hash_value_field – stores parsed values as a hash value.
emit_invalid_record_to_error – applies the @ERROR label for debugging.

filter_stdout
The filter_stdout plugin prints matching events to stdout. This plugin is helpful for debugging, as it can be used to check post-filter output at any point in the data processing flow.

The filter_stdout plugin can use the <format> subdirective to call a formatter plugin to format the outgoing event. The filter_stdout plugin also supports the <inject> subdirective for injecting values into the event record. More information about injecting values can be found in Lab 2.

Third Party Filter Plugins
There are many third party filter plugins available for Fluentd. The Fluentd website provides links to most community plugins.

Many of these plugins expand upon or improve the functionality of the core plugins, such as record_modify which provides higher performance for certain transformations supported by filter_record_transformer, or filter_ua which allows user agent metadata to be added to events as they are run through the Fluentd pipeline.

There are also application-specific filter plugins that enrich data with additional information relevant to a particular source, such as the kubernetes_metadata_filter plugin, which will insert information like Kubernetes pod names and API versions. This is shown in the example below.

A pod deletion event as reported by the Kubernetes network agent can be enhanced with additional information like the Docker container ID and the Kubernetes namespace and pod name.

Without Kubernetes metadata plugin:

2021-05-04 18:51:12.613497781 -0700 kubernetes.var.log.containers.weave-net-87cbm_kube-system_weave-npc-e0446a9d0....log: {"log":"INFO: 2019/03/25 18:46:36.814154 deleted entry 10.32.0.9 from weave-k?Z;25^M}|1s7P3|H9i;*;MhG of d8b32569-4f2d-11e9-b253-000c2959fbde\n","stream":"stderr"}

With Kubernetes metadata plugin:

2021-05-04 18:53:23.326158411 -0700 kubernetes.var.log.containers.weave-net-87cbm_kube-system_weave-npc-e0446a9d0....log: {"log":"INFO: 2019/03/25 18:48:31.017944 deleted entry 10.32.0.9 from weave-k?Z;25^M}|1s7P3|H9i;*;MhG of 74014f85-4f2e-11e9-b253-000c2959fbde\n","stream":"stderr","docker":{"container_id":"e0446a9d0c..."},"kubernetes":{"container_name":"weave-npc","namespace_name":"kube-system","pod_name":"weave-net-87cbm"}}

Finally, there are third party plugins that add all new functionality, such as the ability to ignore events using the filter_plugin_ignore_filter or the ability to automatically anonymize event record data with the filter_plugin_anonymizer.

Output Filter Plugins
Some use cases require filtering functionality that cannot be addressed by a filter directive. For example, the rewrite-tag-filter plugin is an output filter plugin and, like other output plugins, configured in a match directive.

Some existing core filter plugins were actually output filter plugins in earlier versions of Fluentd, such as the filter_parser. Some legacy configurations of Fluentd may include filters that are configured as match directives, though for the most part these filters have been deprecated and their documentation should say so.

 

Filter Plugins
Mutating, filtering, calculating events

CERTIFIED	DOWNLOAD	NAME	AUTHOR	ABOUT	VERSION
Yes	22600338​	rewrite-tag-filter	Kentaro Yoshida​	Fluentd Output filter plugin. It has designed to rewrite tag like mod_rewrite. Re-emmit a record with rewrited tag when a value matches/unmatches with the regular expression. Also, you can change a tag from apache log by domain, status-code (ex. 500 error), user-agent, request-uri, regex-backreference and so on with regular expression.	2.4.0
 

To see more examples, visit the Fluentd plugin website.

Filters in Processing Pipelines
A processing pipeline can be created by combining source, filter and match directives. These pipelines can be simple, employing one filter, or very complex, employing multiple filters in sequence. Most filters are configured using filter directives, though some filter-like plugins can be utilized to achieve the same goals with match directives.

The primary consideration in pipeline creation is the information that needs to be extracted from input events and what limitations those data or events may have when they are output from the sources. If the data are scattered across many logs in many files, then the aggregation function may need to be augmented by some standardization. Sources may have completely different and incompatible formats. Another consideration is that not all data is valuable to all consumers; by using filters, the most valuable and meaningful data can be output to destinations where it can be most effectively and efficiently consumed and managed.

Plugin selection for the filtering pipeline is important; being aware of the content requirements for the data at the destinations is important and will dictate what specific plugins should be chosen. The selected plugins can then be configured to deliver the best event data.



Chapter Summary
The Fluentd filter directive allows filter plugins to be inserted between Fluentd inputs (source) and outputs (match).

Fluentd comes with a capable set of core filter plugins.

Third party filter plugins can be used to extend core filter plugin capabilities

Chapter Overview
As discussed in Chapter 5, Fluentd’s filtering capability is heavily dependent upon record data conforming to the JSON format.

For this reason, Fluentd provides a large set of core parsers capable of reading data in a range of formats and converting that data into JSON formatted key-value pairs, which can be used readily by Fluentd’s internal pipeline components, like filter directives. Parsing is most commonly performed at the beginning of a pipeline in the source directive.

Once pipeline processing is complete, JSON may no longer be the desired format. A formatter plugin can convert JSON data used by Fluentd into the target system’s desired format (e.g. CSV or syslog). Formatters perform the opposite function of a parse and are most commonly configured in match (output) directives.

This chapter will describe how to configure parse and formatting components to effectively process events in a wide range of input and output formats.

Learning Objectives
By the end of this chapter, you should be able to:

Understand the benefits of parsing log data in the logging layer.
Explore Fluentd's data parsing features.
Use predefined and custom parsing schemes.
Demonstrate the use of formatters to align data with output targets.

Data Parsing
Fluentd can be configured to ingest data from a wide variety of sources; in many cases, those sources will emit logged events in a format that may require some effort to parse and understand (logs often consist of single lines of raw data without headers or delimiters). When Fluentd receives log data, by default, it captures the data as is.

Data parsers allow Fluentd to reorganize unstructured data into a format that can be easily read by humans and machines. Parsers do this by separating the data into unique key-value pairs and representing it in JSON format. The keys can then be used by logic in filter directives and other components of a Fluentd logging pipeline.

# Raw log data:

$ cat /var/log/apache2/access.log

127.0.0.1 - - [05/May/2021:15:08:07 +0000] "GET / HTTP/1.1" 200 11173 "-" "curl/7.68.0"

# Fluentd Parsed Event (Using Apache parser):

20210505T150807+0000,apache2.access,{"host":"127.0.0.1","user":null,"method":"GET","path":"/","code":200,"size":11173,"referer":null,"agent":"curl/7.68.0"}

In the example above, an Apache access log is depicted with all of its access event information in a single line without any headers or keys to identify the data values. The Fluentd apache2 parser converts this raw web access event data into a structured JSON document with machine identifiable keys and values. This can then be forwarded to a selected destination as-is or further filtered and processed to extract more value from the data.


Fluentd No Parsing
The example illustrates a Fluentd parsing configuration.

# Example Fluentd config file with no Parsing configured

$ cat parser.conf

<source>
  @type tail
  path /var/log/apache2/access.log
  pos_file /tmp/apache_access.pos
  tag apache2.access
  <parse>
    @type none
  </parse>
</source>
<match>
  @type stdout
</match>

# Make a request to generate access log output in /var/log/apache2/access.log

$ curl http://localhost

# Fluentd log output collected by tailing /var/log/apache2/access.log

$ tail -1 ./fluentd.stdout.capture

2021-05-05 15:14:15.719568926 +0000 apache2.access: {"message\"-\"":"127.0.0.1 - - [05/May/2021:15:14:15 +0000] \"GET / HTTP/1.1\" 200 11173 \"curl/7.68.0\""}

The configuration is set to track logs from an Apache web server using the input tail plugin (in_tail). The tail plugin supports the parse subdirective. The configuration sets the parse subdirective parser plugin type to none, which emits the original event line inside a single message key prefixed with the Fluentd timestamp and input tags. Note the different timestamp values—the Apache timestamp recoded inside the message and the Fluentd timestamp prepended to the message reflecting the Fluentd processing time.


Fluentd Parsing
The example configuration below uses the apache2 parser plugin to parse the input data. With the parser engaged, the same access log data used in the previous example produces very different output. The apache2 parser knows the format and purpose of each field in an apache log entry and splits the event data into separate key-value pairs. The parser also uses the original log's timestamp as the timestamp of the resulting event. Since the access log timestamp does not include milliseconds the parsed message shows zeros for the timestamp milliseconds field.

# Example Fluentd config file with Apache2 Parsing configured

$ cat parser.conf

<source>
  @type tail
  path /var/log/apache2/access.log
  pos_file /tmp/apache_access.pos
  tag apache2.access
  <parse>
    @type apache2
  </parse>
</source>
<match>
  @type stdout
</match>

# Make a request to generate access log output in /var/log/apache2/access.log

$ curl http://localhost

# Fluentd log output collected by tailing /var/log/apache2/access.log

$ tail -1 ./fluentd.stdout.capture

2021-05-05 15:31:31.000000000 +0000 apache2.access: {"host":"127.0.0.1","user":null,"method":"GET","path":"/","code":200,"size":11173,"referer":null,"agent":"curl/7.68.0"}


Parse Subdirective
Fluentd supports the <parse> subdirective within source, filter, and match directives.

The @type parameter specifies the parse plugin name/selects the parser plugin within the <parse> directive.
The @prefix indicates that the type parameter is a Fluentd built-in parameter.
However, not all top-level plugins support parsing. For example, in_tail and in_tcp do but in_forward does not. When a source plugin that does not allow parse is required, the parse subdirective can be added to a filter directive to perform the data parsing.

In general, source directives are the best place to use parse, making the restructured data available throughout the rest of the processing chain.

Please consider the following example:

...
<source>
  @type tail
  path /var/log/apache2/access.log
  pos_file /tmp/apache_access.pos
  tag apache2.access
  <parse>    
    @type apache
  </parse>
</source>
...

The parse subdirective replaces the parse parameter, found in older implementations of Fluentd (version 0.12 and below). As of 1.0, the parse parameter is deprecated but still functional. All newly created configuration files should use the parse subdirective.

Parse Subdirective Parameters: types
The types parameter allows users to assign a given data type to a key’s values. For example, if a <parse> directive types parameter is passed the size:string key:datatype pair, any values parsed into the size key will be formatted as strings. In the example, the size key's data type is integer. The second output uses a types parameter to format the data as a string, so the resulting event has quotes around the numeric value for the size key.

# Original Parsed Event

2021-05-05 15:31:31.000000000 +0000 apache2.access: {"host":"127.0.0.1","user":null,"method":"GET","path":"/","code":200,"size":11173,"referer":null, "agent":"curl/7.68.0"}

$ cat parser.conf

<source>
  @type tail
  path /var/log/apache2/access.log
  pos_file /tmp/apache_access.pos
  tag apache2.access
  <parse>
    @type apache
    types size:integer
  </parse>
</source>
<match>
  @type stdout
</match>

$ curl localhost

$ tail -1 ./fluentd.stdout.capture

2021-05-05 15:35:11.000000000 +0000 apache2.access: {"host":"127.0.0.1","user":"-","method":"GET","path":"/","code":"200","size":"11173","referer":"-","agent":"curl/7.68.0"}

The <parse> directive types parameter allows a user to provide a data type for a given field.

Parse Subdirective Parameters: null_value_pattern
Parse subdirectives support various parameters. Two common parameters manage the processing of null values. The first, null_value_pattern, allows a given value pattern to be converted to the JSON null value. The second, null_empty_string, allows empty strings to be treated as JSON null values. In Fluentd the null value, in most cases, is emitted as JSON null (without quotation marks). In JSON, null is an explicitly defined value separate from empty string (""), 0 or any other value.

The null_value_pattern parameter is demonstrated below. In the original parsed event, the user and referrer keys have a hyphen value. Using the null_value_pattern parameter in the displayed configuration converts these values into null.

# Original Parsed Event

2021-05-05 15:35:11.000000000 +0000 apache2.access: {"host":"127.0.0.1","user":"-", "method":"GET","path":"/","code":"200","size":"11173","referer":"-","agent":"curl/7.68.0"}

$ cat fluentd.conf

<source>
  @type tail
  path /var/log/apache2/access.log
  pos_file /tmp/apache_access.pos
  tag apache2.access
  <parse>
      @type apache
      null_value_pattern -
  </parse>
</source>
<match>
  @type stdout
</match>

$ curl localhost

$ tail -1 ./fluentd.stdout.capture

2021-05-05 15:40:30.000000000 +0000 apache2.access: {"host":"127.0.0.1","user":null,"method":"GET","path":"/","code":"200","size":"11173", "referer":null,"agent":"curl/7.68.0"}

Parse Subdirective Parameters: null_empty_string
The null_empty_string parameter is a Boolean that replaces empty strings ("") with null. The example presented below shows a JSON key-value pair, "json":"", being parsed by Fluentd as "json":null.

$ cat fluentd.conf

<source>
  @type forward
</source>
<filter>
  @type parser
  key_name message
  reserve_data false
  <parse>
    @type json
    null_empty_string true
  </parse>
</filter>
<match>
  @type stdout
</match>

$ echo '{"message":"{\"json\":\"\"}"' | fluent-cat mod.5

$ tail -1 ./fluentd.stdout.capture

2021-05-05 15:47:07.463072779 +0000 mod.5: {"json":null}

Parse Subdirective Parameters: time_key
The <parse> subdirective provides a set of common parameters for plugins that support time value manipulation. These parameters allow the user to select specific keys as time providers, to remove or retain the original time key-value pair within the event's record or to replace a time value with the current time:

time_key specifies a key to use for time data (some plugins default to using a specific “time” key for time data, others default to using the current time)
keep_time_key specifies that the selected time key should not be removed from the parsed record
estimate_current_event uses the current time as the timestamp.
There are other common time parameters available to both the <parse> subdirective and the <format> subdirective that will be discussed in detail later in this chapter.

The example syntax presented below demonstrates the use of the time_key parameter. The configuration specifies that the unixtime key should be used as the time source for the record.

$ cat fluentd.conf

<source>
  @type forward
</source>
<filter mod.5>
  @type parser
  key_name record
<parse>
  @type json
  time_key unixtime
</parse>
</filter>
<match mod.5>
  @type stdout
</match> 

$ echo '{"record":"{\"json\":\"true\",\"unixtime\":5}"}' | fluent-cat mod.5 

$ tail -1 ./fluentd.stdout.capture

1969-12-31 16:00:05.000000000 -0800 mod.5: {"json":"true"}

Parse Subdirective Parameters: keep_time_key
The example syntax below demonstrates the use of the keep_time_key parameter. The configuration specifies that the unixtime key should be used as the time source for the record. Compared to the previous slide, the resulting record retains the unixtime key in addition to setting the timestamp.

$ cat fluentd.conf

<source>
  @type forward
</source>
<filter mod.5>
  @type parser
  key_name record
<parse>
  @type json
  time_key unixtime
  keep_time_key true
</parse>
</filter>
<match mod.5>
  @type stdout
</match>

$ echo '{"record":"{\"json\":\"true\",\"unixtime\":5}"}’ | fluent-cat mod.5

$ tail -1 ./fluentd.stdout.capture

1969-12-31 16:00:05.000000000 -0800 mod.5: {"json":"true","unixtime":5}

Common Parser Plugins
Fluentd installs with a variety of parsers that will create keyed values from many common formats and applications. Parser plugin functionality can range from allowing a user to set their own parsing schema to providing prepackaged application and language-specific parsing schemas.

User-defined:

regexp
multi-lines.
Common input formats:

apache2
apache_error
nginx
syslog.
Common output formats:

JSON
MessagePack (msgpack)
CSV (comma-separated values)
TSV (tab-separated values)
LTSV (labeled tab-separated values).
Many third party plugins for a wide range of file and message formats are available from the Fluentd plugin website.​ Some examples include:

 

Parser Plugins
Parse data in input/filter/output plugins

CERTIFIED	DOWNLOAD	NAME	AUTHOR	ABOUT	VERSION
Yes	8588083​	grok-parser	kiyoto, Kenji Okimoto	Fluentd plugin to support Logstash-inspired Grok format for parsing logs	2.6.2
Yes	3391383	multi-format-parser	Masahiro Nakagawa	Multi-format parser plugin for Fluentd	1.0.0
No	92256	jsonish	Alex Yamauchi	Input parser for records which require minor text processing before they can be parsed as JSON	2.0.2
No	85855	esslowquery	Boguslaw Mista	Fluent parser plugin for Elasticsearch slow query and slow indexing log files	1.1.0
No	211971	json-in-json	Gavin M. Roy	Parser plugin that parses JSON attributes with JSON strings in them	​0.1.4


Parsers and Filters
Parsers are typically used to structure log data for future processing, and they allow incoming log data to be organized into keyed values. These keys can be used later with filter directives or match directives that can target specific keys inside an event’s record. Filters can be used to process the parsed fields of a message. For example, a filter can transform existing log data values without modifying the log structure.

In the given example, the "host" key (added by the apache2 parser) is picked up by the record_transformer filter, which then replaces the existing data (the IP address) with the hostname.

The #{} notation tells Ruby to execute the delimited code (Socket.gethostname), replacing the text with the result of the expression, in this case, the host name.

Without parser plugins (or if using the none plugin), an event will be sent as-is through the defined pipeline. This may be desirable for simple log forwarding, where processing is expected to occur at another external point in the logging pipeline or where raw data is preferred.

More complex parsing schemas can be packaged into a plugin, ensuring simple configuration without needing knowledge about how an application formats its logs.

# A record parsed using the Apache parser

2021-05-05 16:01:26.000000000 +0000 apache2.access: {"host":"127.0.0.1","user":null,"method":"GET","path":"/","code":200,"size":11173, "referer":null,"agent":"curl/7.68.0"}

# A filter configured to transform apache2.access tagged messages

<filter apache2.access>
  @type record_transformer
  <record>
    host "#{Socket.gethostname}"
  </record>
</filter>

# The resulting message data

2021-05-05 16:02:23.000000000 +0000 apache2.access: {"host":"labsys","user":null,"method":"GET","path":"/","code":200,"size":11173, "referer":null,"agent":"curl/7.68.0"}

RegExp Parsing
The regexp plugin is the most flexible parsing plugin. It is used as the basis for many application-specific parsing plugins. 

The RegExp parser allows a user to define a regular expression that parses a log message. The regular expression is configured as the value of the expression parameter and needs to be enclosed between forward slashes ‘/’.

The expression below is based on the Apache log format and will break out the host, user and method values of a given event, emitting them in JSON format. The expression uses regex groups (text within parentheses) to identify fields to capture with each group being given a name of the form ?<name>, where “name” becomes the key in the JSON output associated with the value captured.

<parse>
  @type regexp
  expression /^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \[(?<time>[^\]]*)\] (?<method>\S+)?$/
  time_format "%d/%b/%Y:%H:%M:%S %z"
</parse>

The time_format parameter can be used to specify the intended time format for any time values. This utilizes the Ruby strftime function and accepts any legal strftime format. This is automatically applied to fields with the time key and allows Fluentd to properly interpret a wide range of time formats in the data stream.

The end delimiter for a regexp can be followed by one or more single-letter options which control how the pattern can match:

/pattern/i - ignore case
/pattern/m - treat a newline as a character matched by . (a period)
/pattern/x - ignore whitespace and comments in the pattern
/pattern/o - perform #{} (regex interpolation) only once.
While the regexp plugin is extremely flexible, knowledge about the log format (and regex) is required in order to use it effectively.

The multiline Plugin
Some logs print events across multiple lines, for example the ngnix error log. The multiline plugin supplies a simple way to parse such logs.

The multiline plugin skips log message lines until it reaches a line that matches the regular expression set with the format_firstline parameter. Once it finds the first line, it will match lines that are defined in subsequent format# (1-20) parameters, format1...20.

Like the regexp plugin, new record keys will be made with ?<key> entries inside the regular expression.

Please consider the following example:

<parse>
  @type multiline
  format_firstline /^\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2} \[\w+\] (?<pid>\d+).(?<tid>\d+): /
  format1 /^(?<time>\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}) \[(?<log_level>\w+)\]
</parse>



Data Formatting
Some destinations may require events to be formatted in a specific way, such as JSON, MessagePack or CSV. In these cases, Fluentd formatting plugins can be used to convert events into the desired format, typically within a match (output) directive.

Filters and format plugins extend and simplify Fluentd’s data formatting capabilities. Parsing data into keys and values is almost always the first step in a data processing pipeline.

The following example takes an event from an Apache access log (parsed by the Fluentd apache2 plugin in a source directive), then uses the formatter_hash plugin to convert the JSON data into a Ruby hash (within a match directive).

# Raw web log data

127.0.0.1 - - [05/May/2021:16:04:05 +0000] "GET / HTTP/1.1" 200 11173 "-" "curl/7.68.0"

# Apache parser log data

2021-05-05 16:04:05.000000000 +0000 apache2.access: {"host":"127.0.0.1","user":null,"method":"GET","path":"/","code":200,"size":11173,"referer":null,"agent":"curl/7.68.0"}

# Ruby hash formatter log data

{"host"=>"127.0.0.1", "user"=>nil, "method"=>"GET", "path"=>"/", "code"=>200, "size"=>11173, "referer"=>nil, "agent"=>"curl/7.68.0"}

Format Subdirectives
<format> subdirectives can be used within <filter> and <match> directives if the respective filter or output plugin supports formatting. Not all filter or output plugins support format subdirectives, but typically those that support text formatting support the format subdirective as well.

The timestamp of an outgoing event can be changed using plugin-agnostic parameters. These common time-related parameters will be discussed later in the chapter.

The <format> subdirective replaces the "format" parameter used in older implementations of Fluentd (version 0.12 and below).

The formatter plugin is selected with the @type parameter as usual.

Please consider the following example:

<match apache**>
  @type stdout
  <format>
    @type out_file
    output_tag true
    output_time true
    time_format %y/%m/%d - %H:%M:%S
  </format>
</match>

Formatter Plugins
Fluentd installs with built-in formatter plugins that cover most of the formats found in parser plugins. Formatters are also available as third party plugins.

Use-case specific formats:

stdout
single_value
out_file.
Common formats:

JSON
MessagePack
CSV (comma-separated values)
TSV (tab-separated values)
LTSV (labeled tab-separated values).
The following table shows available formatter plugins​.

 

Formatter Plugins
Format events in output plugins​

CERTIFIED	DOWNLOAD	NAME	AUTHOR	ABOUT	VERSION
No	69602​​	formatter_sprintf	Hiroshi Toyama	Fluentd free formatter plugin, use sprintf	​0.1.0
No	5638​	formatter_simple_tsv	Hiroshi Hatake	Fluentd Simple TSV formatter plugin	0.1.0
No	10255	avro	Shun Takebayashi	Avro formatter plugin for Fluentd	1.1.1
No	7577​	formatter_pretty_json	Yoshihiro Miyai	Fluentd formatter plugin for formatting record to pretty json	1.0.0
​No	2277	formatter_linebyline	Manraj Tatia​	FluentD formatter plugin that formats record output to be shown as key value pairs shown line by line. Only works for FluentD version 0.10.49 and above, and with output plugins that support Text Formatter (such as out_file).	0.0.1
No	2232	formatter_tsv	Naotoshi Seo​	Fluentd TSV formatter plugin	0.0.1
No	2798	arrow	joker1007​	Apache Arrow formatter plugin for Fluentd	​0.0.4
 

To see more examples, visit the Fluentd plugin website.

Formatter Plugin Example
This example session shows the processing output of some sample data, with and without the hash formatter plugin:

$ cat fluentd.conf

<source>
  @type forward
</source>
<match>
  @type stdout
</match>

$ echo '{"module":"5"}' | fluent-cat mod.5

2021-05-05 16:14:07.834623648 +0000 mod.5: {"module":"5"}

$ cat fluentd.conf

<source>
  @type forward
</source>
<match>
  @type stdout
  <format>
    @type hash
  </format>
</match>

$ echo '{"module":"5"}' | fluent-cat mod.5

{"module"=>"5"}

Timestamp Manipulation
<parse> and <format> subdirectives share a set of time-related parameters. These parameters allow a user to adjust the timestamp format:

time_type - determines what time format will be used to parse or format the data (float, Unix time, string)
time_format - when the time type is specified, this allows a custom time format to be set (uses Ruby strptime)
localtime or utc - [Boolean] mutually exclusive, used to determine which relative time reference to use
timezone - [Boolean] determines if the time zone is rendered.
Please consider the following examples:

$ cat parser.conf

<source>
  @type forward
</source>
<filter mod.5>
  @type parser
  key_name record
<parse>
  @type json
  time_key unixtime
  time_type string
  time_format %Y-%m-%d %H:%M:%S
</parse>
<filter>
<match mod.5>
  @type stdout
</match>


$ echo '{"record":"{\"json\":\"true\",\"unixtime\":\"2021-05-05 12:16:00\"}"' | fluent-cat mod.5

2021-05-05 12:16:00.000000000 +0000 mod.5: {"json":"true"}

$ cat formatter.conf

<source>
  @type forward
</source>
<match **>
@type stdout
 <format>
   @type out_file
   output_tag true
   output_time true
   time_format %y/%m/%d - %H:%M:%S
 </format>
</match>

$ echo '{"module":"5"}' | fluent-cat mod.5

21/05/05 - 19:17:59 mod.5 {"module":"5"}

Chapter Summary
Parser plugins, typically, ingest raw log data and break it into key-value pairs, typically formatted in JSON.

Many common formats and application use cases are covered by parsers.

Format plugins allow values in log streams to be transformed into new representations for output.

Parser and formatter plugins provide complementary functions and are often used together in data processing pipelines:

Parsers in source directives (input)
Formatters in match directives (output).

Chapter Overview
This chapter will introduce labels and the @include parameter.

You will learn how to use labels to establish independent processing pipelines within a single configuration file.

You will also learn how to use the @include parameter to import directives from other files.

Upon completion of this module, you will be able to effectively reuse configuration elements making it easier to scale Fluentd deployments.


Learning Objectives
By the end of this chapter, you should be able to:

Explore best practices for organizing Fluentd configuration files.
Learn how to use labels to group filter and match directives.
Learn about the @include directive and how it can be used in a DevOps environment.

Fluentd Configuration File Organization
Fluentd routes all incoming data and logs using tags. Tags are attached to log events by the program generating the data or by source directives. Tags flow through the pipeline with the event until the event is eventually removed from a pipeline by a match directive. A tagged event is only processed if its tag matches a filter or match directive’s pattern.

The order of the directives matters—once an event is processed by a match directive, the event is removed from the processing pipeline and no other directives can process that event.

The diagram shows the path of an example event. Since the event has the tag example, it will be transformed by the filter and output to stdout by the first match directive. The event will not be sent to MongoDB by the last match directive.

In addition to tags, Fluentd also supports labels which work in a similar fashion to tags but allow the config file to control routing independently of input event tags when needed.


Labels
Labels are a configurable routing and grouping method. They consist of an @label parameter and a matching <label> directive. The @label parameter is like a GoTo statement; it allows a configuration to move an event directly into a specific processing pipeline before tag processing begins. Labels group <filter> and <match> directives together into processing pipelines using the label directive.

The @label parameter can be set in a <source> or <match> directive. Events are then forwarded to the designated <label> directive, allowing label directives to capture a labeled event in the same way a filter or match directive captures a tagged event.

The presented image shows a Fluentd configuration with the elsewhere label. This configuration diagram has three sources, a pair of catch-all filter and match directives (as denoted by the ** pattern which matches all tags), and a label directive at the end. Since configuration order matters, any event emitted from both Source 1 and Source 3 will be captured by the <filter **> directive and then the <match **> directive.

Source 2, which sets the elsewhere label in its parameters, will have its events sent directly to the <label elsewhere> directive at the end of the configuration file (which encloses a pair of <filter> and <match> directives). Without the label, the events from Source 2 would have been captured by the <filter> and <match> directives in the middle of the configuration file and removed from further processing by Fluentd.

While labels are usually user-defined, there are two built-in labels: @ERROR and @FLUENT_LOG. These are useful for debugging and will be covered in Chapter 10.

Label Rules
All label parameters must have a corresponding <label> directive or else Fluentd will fail to start and report a configuration error.

@label parameters can be added to <source> and <match> directives. They cannot be used with filter plugins or <filter> directives.

Labels can be redefined using the relabel plugin. The relabel plugin will forward an event to a new label without rewriting or removing the event tags. The relabel plugin can be used to unify multiple output streams into a single stream.

 

A source listening on the Fluentd socket sending its events to the label debug

 

The diagram shows a source listening on the Fluentd socket sending its events to the label debug. Two <match> directives are set within the debug label. One directive matches for events tagged valid and labels them with the view label (using the relabel output plugin). The other <match> directive sends all other events to /dev/null. In the view label directive there is a single match directive outputting the valid events to stdout.

Label (Example)
The example below demonstrates a Fluentd configuration that uses a label.

$ cat fluentd.conf

<source>
  @type forward  
</source>
<source>
  @type forward
  port 24300
  @label guestbook
</source>
<match **>
  @type file
  path /tmp/mod6.other.log
</match>
<label guestbook>
  <match>
    @type file
    path /tmp/mod6.log
    <format>
      @type msgpack
    </format>
  </match>
</label>

$ echo '{"message":"{\"mod6\":\"slide 10\"}"' | fluent-cat mod.6 \
; echo '{"message":"{\"mod6\":\"label\"}"' | fluent-cat guestbook -p 24300

$ pkill -sigusr1 fluentd

$ cat /tmp/mod6.log.20210505_0.log

��message�{"mod6":"label"}

$ cat /tmp/mod6.other.log.20210505_0.log

2021-05-05T15:36:20-07:00     fluent.info {"worker":0,"message":"fluentd worker is now running worker=0"}
2021-05-05T15:36:29-07:00     mod.6 {"message":"{\"mod6\":\"slide 10\"}"}

When an event is received from port 24300, it is assigned the guestbook label. All other events routed to port 24220 (the default for the forward plugin) will be sent to a series of logs prefixed with /tmp/mod6.other.log.

Within the guestbook label, all events are sent to a series of logs prefixed with mod6.log in msgpack format. This occurs even though the guestbook label follows the catch-all <match> directive in the configuration file. The events coming from 24300 are routed to the guestbook label immediately after being received and are never processed by the catch-all <match> directive.

Once events are sent to Fluentd and the output buffers are flushed, the resulting log files can be read using cat. In the mod6.log.* file, only the event sent to port 24300 with the guestbook tag is found in msgpack format. The other events, including the Fluentd startup message, are found in the mod6.other.log files. The label allowed events sent to port 24300 to be separated into their own pipeline.
Label Benefits
Labels provide several organizational benefits:

Readability can be improved using labels, especially in very long and complex configurations. For example, labeled sources can be more easily traced by following the @label parameter to a <label> directive that uses the same string. That <label> directive will only contain the <match> and <filter> directives that affect events using that label. For users trying to debug or understand the functionality of complex configurations, labels help by partitioning directives into separate pipelines.
Another benefit of labels is directive isolation. Directives are executed sequentially inside a configuration file. For configurations with many filters or complex data pipelines, a strict order must be observed to ensure that tagged events are pulled through all their configured filters and are removed from the configuration pipeline at the correct <match> directive. Using labels, <filter> and <match> directives are less likely to affect events that they are not meant to process.
<source>
  @type forward
  @label application
</source>

<source>
  @type tail
  tag example
  ...
</source>

<filter example>
  @type record_transformer
  <record>
  ...
  </record>
</filter>

<match example>
  @type stdout
</match>

<match **>
  @type ...
</match>

<label application>
# For application v1
  <match **>
    @type file
    ...
  </match>
</label>

Reasons to Modularize Fluentd Configurations
The @include directive allows one Fluentd configuration file to include the directives defined in another configuration file. This feature gives users the ability to modularize complex configurations into manageable, simpler units.

@include /etc/fd/nginx.conf
@include cassandra.conf
<source>
  @type forward
...

There are several reasons to modularize Fluentd configurations.

Breaking up long configuration files can make it easier to maintain them. The example below shows an abbreviated Fluentd configuration file that uses multiple sources, a label, and a complex <match> directive. As this configuration grows over time, portions of it may be used in other configurations or it may simply grow too long to be practically serviceable.

Shorter Fluentd configurations are easier to develop, maintain and debug. Individual files can be redeveloped, updated, deprecated, tested and deleted independently (better for version control).

Another reason to modularize Fluentd configurations is to facilitate reuse of known-good configurations and directives. Configuration files themselves can become abstractions for handling data from their configured sources; they can be called without requiring the user to have knowledge about how the data needs to be processed.

All of the above benefits can be achieved using the @include directive.

<system>
  rpc_endpoint 0.0.0.0:24444
</system>

<source>
  @type dummy
  tag test
</source>
<source>
  @type forward
  @label @raw
</source>

<label @raw>
  <match>
    @type stdout
  </match>
</label>

<match test>
  @type forward
  <buffer time,tag,message>
    @type memory
    timekey 2s
    timekey_wait 1s
    flush_mode interval
    flush_interval 1s
  </buffer>
  <server>
    host 0.0.0.0
    port 24224
  </server>
...

@include
@include is a directive that can be used at the top level of a Fluentd configuration file. It allows a user to import directives found inside one configuration file for use in another configuration file.

On startup, Fluentd imports @include files before processing any events. The included directives replace the @include directive in the importing file. Users should consider the resulting overall directive order when using @include.

Fluentd supports nested @include parameters. Allowing one file to include another file that itself includes still other files, e.g. FileA includes FileB, FileB includes FileC, FileC includes FileD, etc. This allows configuration hierarchies to be constructed.

Configuration files can be imported from the current directory, an absolute path on the local filesystem, a network directory, or from the web.

The presented diagram models a single Fluentd.conf configuration file importing three other configuration files from various locations, a web URL, a local filesystem file and a network share.

@include Rules
When using @include, there are certain rules that need to be followed.

Like in all Fluentd configurations, included directives will be executed in the order that they appear in the file. If a specific order of directives is required, then the include statements should follow that order.

All directives that are loaded must fulfill their syntax requirements. They must be well-formed, following standard configuration file formatting rules. In other words, each directive should be able to load on its own.

When selecting files to include, there are several ways to specify files: by specifying absolute (full) paths, by using the paths relative to the current directory, and by specifying remote URLs. Wildcards can be used with absolute and relative paths, but not with remote URLs. Environment variables are not supported in path name expressions.

Configuration files can contain their own @include statements, chaining configurations together.



@include Configuration File Syntax
A configuration file can be written only with @include statements. In the configuration file presented below, the sources, filters and outputs have all been separated into their own configuration files in various local and remote locations.

$ cat fluentd-include.conf

# Relative path
# Fluentd will look in user’s current directory for the specified file
@include sources.conf

# Absolute path
# To specify exact configuration file location
@include /var/fluentd/.conf/filter_msgpack.conf

# Absolute path using a wildcard
# To grab all stdout configurations
@include /var/fluentd/.conf/filter_stdout_*.conf

# Remote URL to pull configurations from a centralized repository
@include htt‌ps://repo.organization.io/git/fluentd/configs/outputs.conf

<system>
  suppress_config_dump true
</system>

The @include parameter for the sources.conf file is using a relative path. If the user specifies only the file name, Fluentd will attempt to load the file from the current working directory (the directory in which Fluentd was executed).

The first set of filters is referred to with an absolute path, so Fluentd will look in that explicit path for the configuration file.

For the second set of filters, a wildcard is used to import all configurations starting with "filter_stdout_" in the directory. Each of the filter_stdout_* configurations will be loaded in lexical order, so filter_stdout_json will be loaded before filter_stdout_msgpack.

If the Fluentd host can communicate with the target host over http(s), a remote URL can be used to retrieve configurations from an online or network location. The only requirement for the file is that it only contains the text of the directives. If configurations are being pulled from GitHub, be sure to retrieve the raw content of a configuration file from the raw.githubusercontent.com URL.

This example configuration file has a system directive that configures Fluentd to suppress the initial configuration dump. Once this configuration file is loaded, it will not show any information about the final configuration. By using @include statements with that option, configurations can be made more private.


@include Configuration File
The following examples demonstrate the use of @include statements. 

In this case, a user has split their Fluentd <source> directives and <match> directives into two separate files, sources.conf and matches.conf. Both of these configuration files can be loaded to run independently since the directives inside are well-formed and valid. However, the resulting Fluentd instance will not be functional because neither configuration file contains a completed pipeline.

$ cat sources.conf

<source>
  @type forward
  port 32766
</source>

<source>
  @type http
  port 32767
</source>

<source>
  @type tail
  path /tmp/app.log
  pos_file /tmp/app.log.pos
  tag mod.6
  <parse>
    @type none
  </parse>
</source>

$ cat matches.conf

<match mod.*>
  @type file
  path /tmp/app/logs/aggregate
</match>

<match>
  @type null
</match>

To create a complete pipeline using these configuration files, a third configuration file called fluentd.conf is written.

$ cat fluentd.conf

@include /home/ubuntu/mod6/sources.conf
@include /home/ubuntu/mod6/matches.conf

It will use @include to load directives from both sources.conf and matches.conf. The order of the configuration files matters, since one contains only <source> directives and the other contains only <match> directives.

When Fluentd is loaded using fluentd.conf, it will load the directives from both sources.conf and matches.conf as though they were directly written inside fluentd.conf. After parsing the configuration files, Fluentd evaluates whether the directives are correctly formed. If all directives are correctly formed, it will proceed with normal operation. If the configuration files were loaded in reverse order, the parsed configuration files would have had the <match> directives loaded before the <source> directives. In that case, Fluentd will still be able to load, but it will have a non-functional pipeline.

$ fluentd -c fluentd.conf

2021-05-05 23:51:50 +0000 [info]: parsing config file is succeeded path="fluentd.conf"
2021-05-05 23:51:50 +0000 [info]: gem 'fluent-plugin-formatter_pretty_json' version '1.0.0'
2021-05-05 23:51:50 +0000 [info]: gem 'fluentd' version '1.12.2'
2021-05-05 23:51:50 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    port 32766
  </source>
  <source>
    @type http
    port 32767
  </source>
  <source>
    @type tail
    path "/tmp/app.log"
    pos_file "/tmp/app.log.pos"
    tag "mod.6"
    <parse>
      @type "none"
    </parse>
  </source>
  <match mod.*>
    @type file
    path "/tmp/app/logs/aggregate"
    <buffer time>
      path "/tmp/app/logs/aggregate"
    </buffer>
  </match>
  <match>
    @type null
  </match>
</ROOT>
2021-05-05 23:51:50 +0000 [info]: starting fluentd-1.12.2 pid=3663 ruby="2.7.0"

Benefits of @include
There are several benefits to using @include statements for Fluentd configuration files:

Known-good sets of directives and configurations can be used and reused throughout an environment.
@include enables modularization for complex Fluentd configurations, turning them into code that is simple to develop, troubleshoot, maintain and deploy.
Configurations can be kept in a central repository and/or be managed by a version control system which minimizes local Fluentd resource footprint.
Some measure of obfuscation can be provided to Fluentd configurations by using a remote configuration file with the suppress_config_dump system parameter. Fluentd client instances will not hold such sensitive information outside of memory.
The illustration shows that a single configuration file (fluentd-endpoint.conf) can be used to drive multiple Fluentd instances with configurations containing a single @include statement (local.conf).



Chapter Summary
Fluentd supports configuration file readability and portability.

Labels are a way of organizing directives for readability and execution simplicity.

@include statements can be used to modularize Fluentd configurations.

The combination of labels and @include statements allows Fluentd configurations to be easily maintained as code.

Chapter Overview
This chapter will discuss how multiple instances of Fluentd can power a unified logging layer. You will learn about various use cases and Fluentd multi-instance architectures that facilitate high availability and distributed processing.

In addition, you will examine several practical examples of multi-instance deployments. You will also take a look at how these deployments behave and operate.

Finally, this chapter will show how multi-instance deployments can be configured for load balancing or high availability to ensure that events are handled in a robust and performant manner.

Learning Objectives
By the end of this chapter, you should be able to:

Examine multi-instance Fluentd deployment architectures.
Explore how Fluentd works in different roles as a log forwarder and aggregator.
Demonstrate how to configure multiple instances of Fluentd.
Learn how to configure multiple aggregators for load balancing or achieving high availability with Fluentd.


Fluentd Roles in Multi-Instance Deployments
Multiple instances of Fluentd can be deployed to enable a unified logging layer. Each Fluentd instance can be configured to perform a different role. There are two roles: log forwarder and log aggregator.

Click on each box to learn more about these roles.

Roles
Close Log Forwarder
A log forwarder is a lightweight Fluentd instance that is installed locally on an application or appliance node. It collects, parses and sends logs to a central Fluentd log aggregator. Log forwarders typically submit events to log aggregators asynchronously to reduce overhead and increase performance.

Close Log Aggregator
A log aggregator is a dedicated Fluentd instance that is configured with complete processing pipelines. These instances receive events from remote log forwarders. Multiple log aggregators can be deployed, either working in tandem for load balancing or in high availability mode with some instances in hot standby mode.

The illustration shows a diagram of a multi-instance Fluentd deployment. To the left is a group of forwarders, with each box representing an application node or appliance containing an instance of Fluentd. Each instance routes events to the right side of the diagram, which contains all of the log aggregators.



There are three log aggregators configured on the right, with two of them having events routed to them. On the bottom of the aggregators section is a single instance of Fluentd, which is configured as a standby node. If either one of the active aggregators goes down, the standby node will take its place

Basic Multi-Instance Deployment
The most basic multi-instance Fluentd deployment consists of at least one forwarder Fluentd instance and one log aggregator.

In the diagram, there are three log forwarders deployed with the IP range of 192.168.0.1-3.

Each forwarder sends its events directly to the log aggregator, represented by the larger box on the right of the diagram. The aggregator processes the received events and ultimately submits them to one or more destinations (e.g. Elasticsearch).

The connection between the forwarders and aggregators does not have to be direct - the forwarders could go through a load balancing mechanism or other abstraction such as a Kuberentes service.


Fluentd as a Log Aggregator
Any Fluentd instance is considered a log aggregator if it ingests events from multiple sources and outputs them to one or more destinations. Fluentd log forwarders emit events to aggregators using the out_forward plugin. This plugin delivers events using the Fluentd protocol in msgpack format (for more information on the Fluentd protocol see "Fluentd Forward Protocol Specification (v1)" Wiki post on GitHub. To receive events from other Fluentd instances, the in_forward plugin is used.

Log aggregator instances are generally given more resources because they perform more processing on events than forwarders and because they typically process events from multiple forwarders. For example, aggregators may perform additional event parsing, process labels, multiple filter directives and multiple match directives. This is of course convention only, you can configure forwarders to bear more of the workload in the logging layer should you have a reason to.

Log aggregators are typically dedicated network entities within a multi-instance Fluentd deployment. They receive a majority of event traffic from forwarders over the network rather than locally. However, a log aggregator can also be more general purpose and can be configured to receive events directly from other, non-Fluentd sources.

The diagram shows a representation of a log aggregator Fluentd instance. This Fluentd instance has two processing pipelines configured that will capture and submit events based on the tags that are assigned by forwarders.

Log Aggregator (Example)
The example below shows a simple log aggregator, which receives an event from the forwarder and prints it to a log file prefixed with aggregator1. It is configured to listen for Fluentd traffic on port 24500 with no authentication. Any forwarders that want to send events to this aggregator need to be configured to send to port 24500 using the Fluentd protocol. This instance can be further configured with additional filters, destinations and even other sources.

$ cat aggregator1/aggregator1.conf

<system>
  process_name aggregator1
</system>
<source>
  @type forward
  port 24500
</source>
<match>
  @type stdout
</match>

$ docker run -p 24500:24500 --name aggregator1 -v $HOME /fluentd/mod7/aggregator1:/fluentd/etc -v /tmp/logs:/logs -e FLUENTD_CONF=aggregator1.conf fluent/fluentd:v1.13.2-1.0

2021-05-06 18:43:11 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/aggregator1.conf"
2021-05-06 18:43:11 +0000 [info]: gem 'fluentd' version ‘1.13.2'
2021-05-06 18:43:11 +0000 [info]: using configuration file: <ROOT>
  <system>
    process_name "aggregator1"
  </system>
  <source>
    @type forward
    port 24500
  </source>
  <match>
      @type stdout
  </match>
</ROOT>
2021-08-06 20:13:52 +0000 [info]: starting fluentd-1.13.2 pid=7 ruby="2.7.0"
2021-08-06 20:13:52 +0000 [info]: spawn command to main: cmdline=["/usr/bin/ruby2.7", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/aggregator1.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2021-08-06 20:13:53 +0000 [info]: adding match pattern="**" type="stdout"
2021-08-06 20:13:53 +0000 [info]: adding source type="forward"
2021-08-06 20:13:53 +0000 [warn]: #0 define <match fluent.**> to capture fluentd
logs in top level is deprecated. Use <label @FLUENT_LOG> instead
2021-08-06 20:13:53 +0000 [info]: #0 starting fluentd worker pid=16 ppid=7 worker=0
2021-08-06 20:13:53 +0000 [info]: #0 listening port port=24500 bind="0.0.0.0"
2021-08-06 20:13:53 +0000 [info]: #0 fluentd worker is now running worker=0

Fluentd as a Log Forwarder
A Fluentd instance configured with the out_forward plugin is considered a log forwarder in a multi-instance Fluentd deployment. The log forwarder is co-deployed with the application(s) it is intended to collect events and data from.

Log forwarders are meant to collect events and then forward them to a log aggregator. To minimize resource consumption on the application host, log forwarder configurations should be kept as lightweight as possible and defer all processing to a log aggregator. Multiple log forwarders can send events to a single log aggregator.

The diagram shows a log forwarder Fluentd instance. The instance sits on the same node as the application and is configured with the out_forward plugin to send events to a log aggregator.



out_forward
The out_forward plugin is used by declaring @type forward in a <match> directive. It enables a Fluentd instance to send events to other Fluentd instances. The primary configuration is provided by the <server> subdirective specifying which log aggregators will collect the forwarded events.

out_forward is a buffered plugin, meaning collected events are first stored in a buffer before being distributed at a specified time interval or buffer size limit. Buffering makes the log forwarding process inherently robust against data lost:

Collected events are written to temporary storage on local disk or memory, to minimize the risk of data loss in a process failure scenario.
In the event of a network failure, chunks of events that failed to send are periodically retried until they succeed.
The out_forward plugin supports secure communication over TLS and password authentication.
out_forward Setup: <server> Subdirective
The primary configuration in the out_forward plugin is the <server> subdirective. Each <server> subdirective configures a unique log aggregator. To configure multiple log aggregators, an out_forward plugin can use multiple <server> subdirectives.

Each <server> subdirective requires connection information that matches a corresponding log aggregator's in_forward configuration.

Click on each box to see what's included.

Connection Information
Close Name
It is a user-defined identifier for the log aggregator.

Close Host (parameter)
It can be an expected IP address or hostname of a log aggregator.

Close Port (parameter)
It is the Fluentd socket port to send event traffic on.

...
<match>
  @type forward
  <server>
    name aggregator1
    host 172.17.0.2
    port 24500
  </server>
</match>
...



Service Discovery
Service discovery functions were released with Fluentd starting in 1.8, allowing Fluentd instances to perform enhanced service discovery if a plugin does not have adequate service discovery capabilities.

Fluentd enables plugins to use service discovery, which allows it to use the static, file, or SRV service discovery plugins to dynamically find endpoints for an output. In a core Fluentd installation, only the out_forward plugin uses the <service_discovery> subdirective. Third party plugins can also use <service_discovery> to provide or enhance that ability if required.

The sd_static plugin allows users to specify a list of targets directly in the configuration file. This list is loaded from the configuration, and requires a restart of Fluentd if the list of targets need to be updated. This is only to be used by plugins that do not already enable users to manually declare endpoints. It is functionally the same as setting the <server> subdirective in an out_forward configuration.
sd_file allows Fluentd to continually read a file formatted in JSON or YAML for service endpoints. Any updates to the file are read by Fluentd and applied dynamically to the list of endpoints. The example on this page shows the contents of a hypothetical file, aggregators.yaml, and the corresponding <match> directive in a Fluentd configuration that uses it.
sd_srv allows a plugin to perform a DNS lookup for a service's SRV records. Users must provide the service name and the domain to perform the lookup on to use this functionality. Optionally, users can also declare a DNS server to use to perform the lookup if necessary.
The Service discovery feature is under active development and more plugins may be added as efforts continue. DNS-based discovery mechanisms will be ideal for cloud native deployments. This feature may be redundant for systems like Kubernetes that already provide service discovery capabilities, though there may be use cases where having both available will be key.

# Contents of aggregators.yaml

- 'host': 127.0.0.1
  'port': 24224
  'weight': 1
  'name': aggregator1
- 'host': 127.0.0.1
  'port': 24225
  'weight': 1
  'name': aggregator2

...
<match>
  @type forward
  <service_discovery>
     @type file
     path /nfs/aggregators.yaml
  </service_discovery>
</match>
...

Log Forwarding (Example)
The example below illustrates a log forwarder configuration using a single log aggregator. The log forwarder tails an application log file on its local filesystem, /tmp/app.log, using the in_tail plugin. It uses the none parser plugin to create a single key-value pair with the event log paired with the "message" key. The event will be tagged with my.application when it is sent to the log aggregator.

The logs collected by the log forwarders are sent to a log aggregator identified over the network by its IP address and port, 172.17.0.2:24500. The <match> directives using out_forward are imported with @include parameter so other log forwarders can send events to the same log aggregator.

When Fluentd starts using this configuration, it will add the configured log aggregator, aggregator1, to a pool of servers receiving events.

~/forwarder$ cat app-forwarder.conf

<system>
  process_name app.forwarder
</system>
<source>
  @type tail
  path /tmp/app.log
  pos_file /tmp/app.log.pos
  tag my.application
  <parse>
    @type none
  </parse>
</source>
<match>
  @type forward
  <server>
    name aggregator1
    host 172.17.0.2
    port 24500
  </server>
</match>

~/forwarder$ fluentd -c app-forwarder.conf

...
2021-07-22 21:51:08 +0000 [info]: starting fluentd-1.13.2 pid= 116120 ruby="2.7.0"
2021-07-22 21:51:08 +0000 [info]: spawn command to main: cmdline=["/usr/bin/ruby2.7", "-Eascii-8bit:ascii-8bit", "/usr/local/bin/fluentd", "-c", "forwarder.conf", "--under-supervisor"]
2021-07-22 21:51:08 +0000 [info]: adding match pattern="**" type="forward"
2021-07-22 21:51:08 +0000 [info]: #0 adding forwarding server 'aggregator1' host="172.17.0.2" port=24500 weight=60 plugin_id="object:2af90d8eb1ac"
2021-07-22 21:51:08 +0000 [info]: adding source type="tail"

With both a log aggregator and a log forwarder up and running, an event that is written to the tailed log, /tmp/app.log, should be forwarded to a log file prefixed with aggregator1.

Since the aggregator is sending logs to a file, the buffer needs to be forcibly flushed with a pkill -sigusr1 command. These events are also written to the buffer (and resulting log) due to the aggregator1 configuration routing all events to that log file.

$ echo "This event should be forwarded" >> /tmp/app.log

$ pkill -sigusr1 fluentd

$ docker logs aggregator1 --tail 5

2021-05-06 18:47:53.451050005 +0000 fluent.info: {"message":"flushing all buffer forcedly"}
2021-05-06 18:47:57.974275501 +0000 fluent.info: {"message":"following tail of /tmp/app.log"}
2021-05-06 18:48:27.003980784 +0000 fluent.info: {"message":"force flushing buffered events"}
2021-05-06 18:48:27.004309458 +0000 fluent.info: {"message":"flushing all buffer forcedly"}
2021-05-06 18:48:24.261698501 +0000 my.application: {"message":"This event should be forwarded"}

High Availability and Load Balancing with Multiple Aggregators
Multiple aggregators can be configured in a Fluentd-driven logging pipeline. Events can be routed to multiple aggregators simultaneously in a load balancing capacity or be set up to fail over and send events to a standby log aggregator.

Load balancing
- To configure multiple log aggregators, each forwarder needs more than one <server> subdirective declared under its out_forward configuration.
- To send events to multiple aggregators for load balancing, no additional configuration is required. An optional weight parameter can be set to determine the ratio with which event submissions are split between aggregators.

High availability
- To configure a log aggregator as a standby instance for high availability, the standby parameter must be declared in one or more of the additional <server> subdirectives on the forwarder.
- Aggregators that are set as standby instances receive no traffic unless an active node is unavailable.

The diagram depicts an array of aggregators. It illustrates two aggregators used for load balancing and a third aggregator, highlighted in red, marked as a standby aggregator. Should either of the active aggregators in this diagram become unreachable, the standby node will begin receiving events. If a down aggregator returns, the standby aggregator will stop receiving events.

Load Balanced Deployment
In a load balanced deployment, each log forwarder is set up to send events to multiple log aggregators.

The distribution of events is influenced by the weight parameter on each log forwarder. The default weight is 60. If all aggregators have the default weight, each will get an even share of events. In a two aggregator configuration, if one has a weight of 60 and one has a weight of 30, the aggregator with a weight of 60 will receive two events for every one sent to aggregator 2 (60/30 ratio).


Load Balanced Deployment (Example 1)
In this configuration, the forwarder is configured with three destination servers. All configured servers are treated as active log aggregators since the standby parameter in each <server> subdirective is set to false or is omitted.

The weight on each destination server is set to 50 to create an even distribution of events between the servers.

When Fluentd is started with this configuration, it adds the configured servers as "forwarding" servers, and begins continually sending heartbeats to them.

~/forwarder$ cat lb-forwarder.conf

<system>
  process_name app.forwarder
</system>
<source>
  @type tail
  path /tmp/app.log
  pos_file /tmp/app.log.pos
  tag my.application
  <parse>
    @type none
  </parse>
</source>

# Pull aggregator configs from centrally located file
@include /home/ubuntu/forwarder/lb-aggregators.conf

~/forwarder$ cat lb-aggregators.conf

<match>
  @type forward
  require_ack_response true
  <server>
    name aggregator1
    host 172.17.0.2
    port 24500
    weight 50
    standby false
  </server>
  <server>
    name aggregator2
    host 172.17.0.3
    port 25500
    weight 50
  </server>
  <server>
    name aggregator3
    host 172.17.0.4
    port 26500
    weight 50
    standby false
  </server>
</match>

$ fluentd -c lb-forwarder.conf

...
2021-05-06 11:56:35 -0700 [info]: #0 adding forwarding server 'aggregator1' host="172.17.0.2" port=24500 weight=50 plugin_id="object:2b1d6d606c00"
2021-05-06 11:56:35 -0700 [info]: #0 adding forwarding server 'aggregator2' host="172.17.0.3" port=25500 weight=50 plugin_id="object:2b1d6d606c00"
2021-05-06 11:56:35 -0700 [info]: #0 adding forwarding server 'aggregator3' host="172.17.0.4" port=26500 weight=50 plugin_id="object:2b1d6d606c00"...

Load Balanced Deployment (Example 2)
This example shows events being sent through the load balanced Fluentd deployment discussed in the last examples. The watch command is used to send events to /tmp/app.log every second. After a few seconds of running, the watch command is cancelled with CTRL+C.

$ watch -n 5 'echo "This event should be load balanced" >> /tmp/app.log'

...
^C

$ pkill -sigusr1 fluentd

$ docker logs aggregator1 --tail 5

2021-05-06 18:58:29.922840397 +0000 my.application: {"message":"This event should be load balanced"}
2021-05-06 18:58:30.928835963 +0000 my.application: {"message":"This event should be load balanced"}
2021-05-06 18:58:31.936163527 +0000 my.application: {"message":"This event should be load balanced"}
2021-05-06 18:58:41.303020448 +0000 fluent.info: {"message":"force flushing buffered events"}
2021-05-06 18:58:41.303573407 +0000 fluent.info: {"message":"flushing all buffer forcedly"}
...

$ docker logs aggregator2 --tail 5

2021-05-06 18:55:08.753646474 +0000 fluent.info: {"worker":0,"message":"fluentd worker is now running worker=0"}
2021-05-06 18:59:44.572488368 +0000 fluent.info: {"message":"detected rotation of /tmp/app.log"}
2021-05-06 18:59:44.572558496 +0000 fluent.info: {"message":"following tail of /tmp/app.log"}
2021-05-06 19:00:09.178626868 +0000 fluent.info: {"message":"force flushing buffered events"}
2021-05-06 19:00:09.178794939 +0000 fluent.info: {"message":"flushing all buffer forcedly"}
...

$ docker logs aggregator3 --tail 5

2021-05-06 19:00:01.291769765 +0000 my.application: {"message":"This event should be load balanced"}
2021-05-06 19:00:02.297117539 +0000 my.application: {"message":"This event should be load balanced"}
2021-05-06 19:00:03.302279457 +0000 my.application: {"message":"This event should be load balanced"}
2021-05-06 19:00:04.308122340 +0000 my.application: {"message":"This event should be load balanced"}
2021-05-06 19:00:05.313579258 +0000 my.application: {"message":"This event should be load balanced"}

To see how the events were distributed with the load balanced Fluentd configuration, the buffers are force-flushed by sending a sigusr1 to all Fluentd instances. This forces the forwarder to submit its events to the aggregators, and the aggregators to write out the events they received from their buffers.

With a flush occurring, Fluentd distributed some of the forwarded events to aggregator1 and others to aggregator3. aggregator2 did not receive any events at the time of the flush.

Highly Available Deployment
In a highly available deployment, each forwarder is set up to send events to an active aggregator. In the event that contact with an active aggregator is lost, events are forwarded to a standby aggregator.

Standby aggregators do not receive events while all active log aggregators are up.

In the presented diagram, three log forwarders are set up to send events to a pair of load balanced aggregators, represented by gray arrows. If contact with one of the active aggregators is lost, traffic is rerouted to the standby node, represented by a red arrow.


High Availability Configurations
To enable high availability in a multi-aggregator scenario, at least two destination servers must be defined in a forwarder's configuration. One of the servers must have the standby true parameter, which designates the server as a standby server. This server will still be counted in the pool of servers to forward events to, but it will not receive any traffic as long as all of the primary active log aggregators are healthy. If the standby parameter is omitted, it is treated as false and the server is treated as an active aggregator.

High availability can be used alongside load balancing, with one or more standby log aggregators configured to handle traffic when a log aggregator is lost. The weight parameter can be set on the standby node to ensure that the desired event distribution is preserved in case of log aggregator failure.

$ cat ha-aggregators.conf

<match>
  @type forward
  <server>
    name aggregator1
    host 172.17.0.2
    port 24500
    weight 50
  </server>
  <server>
    name aggregator2
    host 172.17.0.3
    port 25500
    standby true
    weight 50
  </server>
  <server>
    name aggregator3
    host 172.17.0.4
    port 26500
    weight 50
    standby false
  </server>
</match>

Highly Available and Load Balanced Deployment
The following example shows a highly available and load balanced configuration. There are two active aggregators, aggregator1 and aggregator3, both evenly distributing events with a weight of 50. The second server, aggregator2, is designated as the standby node in this deployment. It is configured with the standby true parameter and retains the same weight value of 50 to ensure the event distribution remains the same in a failover scenario.

When started, Fluentd initializes in the same way as a load balanced configuration. All configured nodes, including the standby node, are added as forwarding server. Fluentd does not output any indication that one of the nodes is in standby mode.

~/forwarder$ cat ha-file-forwarder.conf

<system>
  process_name forwarder
</system>

<source>
  @type tail
  path /tmp/app.log
  pos_file /tmp/app.log.pos
  tag my.application
  <parse>
    @type none
  </parse>
</source>

@include /home/ubuntu/forwarder/ha-aggregators.conf

~/forwarder$ cat ha-aggregators.conf

<match>
  @type forward
  <server>
    name aggregator1
    host 172.17.0.2
    port 24500
    weight 50
    standby false
  </server>
  <server>
    name aggregator2
    host 172.17.0.3
    port 25500
    weight 50
    standby true
  </server>
  <server>
    name aggregator3
    host 172.17.0.4
    port 26500
    weight 50
    standby false
  </server>
</match>

~/forwarder$ fluentd -c ha-file-forwarder.conf -v

...
2021-05-06 12:07:36 -0700 [info]: #0 adding forwarding server 'aggregator1' host="172.17.0.2" port=24500 weight=50 plugin_id="object:2b25f7ac75cc"
2021-05-06 12:07:36 -0700 [info]: #0 adding forwarding server 'aggregator2' host="172.17.0.3" port=25500 weight=50 plugin_id="object:2b25f7ac75cc"
2021-05-06 12:07:36 -0700 [info]: #0 adding forwarding server 'aggregator3' host="172.17.0.4" port=26500 weight=50 plugin_id="object:2b25f7ac75cc"

Failover Behavior
The example below follows the output of a Fluentd instance using the configuration from the previous pages and experiencing an active aggregator failure.

The log forwarder continually sends heartbeat requests to its configured aggregators. If a heartbeat request is not answered in time, a warning event is emitted. Here, the first failed heartbeat is received at 12:10:38.

After realizing one of the primary nodes is down, the standby node is activated. The user submitted a SIGUSR1 to all Fluentd instances at 12:08, forcing a flush to occur. Since aggregator3 was down at this time, aggregator2 was brought out of standby mode. The forwarder will attempt to reconnect to the failed aggregator from time to time. If the connection can be reestablished and heartbeats resume, the forwarder will place the standby node back into standby mode and resume sending traffic to the recovered active node.

The forwarder will continuously emit error events while an aggregator is down if the instance's verbosity is set high enough.

~/forwarder$ fluentd -c ha-file-forwarder.conf -v

...
2021-05-06 12:10:38 -0700 [debug]: #0 fluent/log.rb:308:debug: failed to send heartbeat packet host="172.17.0.4" port=26500 heartbeat_type=:transport error_class=Errno::ECONNREFUSED error="Connection refused - connect(2) for \"172.17.0.4\" port 26500"
2021-05-06 12:11:09 -0700 [debug]: fluent/log.rb:308:debug: fluentd supervisor process get SIGUSR1
2021-05-06 12:11:09 -0700 [debug]: #0 fluent/log.rb:308:debug: fluentd main process get SIGUSR1
2021-05-06 12:11:09 -0700 [info]: #0 fluent/log.rb:329:info: force flushing buffered events
2021-05-06 12:11:09 -0700 [info]: #0 fluent/log.rb:329:info: flushing all buffer forcedly
2021-05-06 12:11:29 -0700 [debug]: #0 fluent/log.rb:308:debug: flushing thread: flushed
2021-05-06 12:11:31 -0700 [debug]: #0 fluent/log.rb:308:debug: connect new socket
2021-05-06 12:11:46 -0700 [debug]: #0 fluent/log.rb:308:debug: unexpected error happen during heartbeat host="172.17.0.4" port=26500 heartbeat_type=:transport error_class=Errno::EHOSTUNREACH error="No route to host - connect(2) for \"172.17.0.4\" port 26500"
2021-05-06 12:11:46 -0700 [warn]: #0 fluent/log.rb:350:warn: detached forwarding server 'aggregator3' host="172.17.0.4" port=26500 hard_timeout=true
2021-05-06 12:11:46 -0700 [debug]: #0 fluent/log.rb:308:debug: rebuilding weight array lost_weight=50
2021-05-06 12:11:46 -0700 [warn]: #0 fluent/log.rb:350:warn: using standby node 172.17.0.3:25500 weight=50
...

Log Aggregator Recovery
If a down aggregator begins responding again, the log forwarder will immediately reattach to the log aggregator and start sending it events. If a standby node was in use, it will return to standby status and will no longer receive events.

A log aggregator’s network identity must match the server configuration in order to successfully reconnect.

...
2021-05-06 12:12:25 -0700 [debug]: #0 fluent/log.rb:308:debug: failed to send heartbeat packet host="172.17.0.4" port=26500 heartbeat_type=:transport error_class=Errno::ECONNREFUSED error="Connection refused - connect(2) for \"172.17.0.4\" port 26500"
2021-05-06 12:12:26 -0700 [debug]: #0 fluent/log.rb:308:debug: 2021-05-06 12:12:36 -0700 [debug]: #0 fluent/log.rb:308:debug: connect new socket
2021-05-06 12:12:36 -0700 [warn]: #0 fluent/log.rb:350:warn: recovered forwarding server 'aggregator3' host="172.17.0.4" port=26500
2021-05-06 12:12:36 -0700 [debug]: #0 fluent/log.rb:308:debug: rebuilding weight array lost_weight=0
...


Chapter Summary
Multi-instance Fluentd deployments can consist of one or many log forwarders and log aggregators.

Log forwarders are lightweight, local log and event collectors that are configured using the out_forward plugin.

Log aggregators receive events from log forwarders and are dedicated to event processing and distribution.

Multiple log aggregators can be deployed to achieve load balancing and high availability.



Chapter Overview
Unified logging layers provide a single fabric through which applications and appliances can emit log events. The observability function provided by the unified logging layer is critical to almost any application management function. If the logging layer fails, the visibility it provides is lost. It is important to ensure that the logging layer itself is fully functional, not just the applications it supports.

This chapter will discuss the rationale behind deploying monitoring solutions to "watch the watcher" and ways to ensure that the unified logging layer is actually logging. This chapter will also introduce the key metrics associated with a unified logging layer, so users looking to implement monitoring will know what to look for.

Fluentd can be configured to expose its own metrics to a variety of logging tools. The officially recommended approach, which will be discussed in this chapter and later demonstrated in the lab, is to use Prometheus—an open source metrics time series database and monitoring platform, another project under the CNCF umbrella. We will also examine other tools useful for monitoring Fluentd.



Learning Objectives
By the end of this chapter, you should be able to:

Understand why monitoring a unified logging layer is important.
Learn about the key metrics to monitor in a unified logging layer.
Examine the tools available for monitoring Fluentd.
Learn how to monitor Fluentd.

Why Monitor a Unified Logging Layer?
A unified logging layer is a critical component of the infrastructure it is configured to collect data from. Its components, like individual log forwarder and aggregator instances, can be deployed on nodes that are already being monitored by pre-existing tools.

The unified logging layer provides visibility into applications and infrastructure at all levels, from customer-facing production systems to obscure backend systems. The ubiquity from this approach makes a unified logging layer critical to maintaining visibility into the health and operation of those application and infrastructure components.

Without the unified logging layer, the risk of having a critical event increases, especially if the systems it was watching are not easily accessible or well known. The ability to effectively respond to those kinds of events could, at best, be delayed and at worst be completely missed if the unified logging layer is not healthy.

The diagram illustrates how logs, metrics and events must make their way through a logging layer to get to consumers. If the logging layer is lost, then the consumers will have no way of knowing what's happening with applications, nodes, services and other infrastructure in their environment.



Key Metrics
There are a few key metrics that must be considered when creating a strategy for monitoring a unified logging layer.

Click on each box to learn more about them.

Key Metrics
Close Network Connectivity
A unified logging layer is built on the ability to send application and infrastructure events and data over a network to one or more destinations. If the components that comprise a unified logging layer cannot reach the data sources they are configured to pull events from, then visibility is lost for those sources. Likewise, if the unified logging layer cannot submit those collected events to their intended destinations, then the intended consumers lose visibility into the data.

It is important to keep an eye on network connectivity when monitoring a unified logging layer to ensure that events are collected and received for further processing and distribution.

The diagram shows how all data traffic (logs, metrics and events) are routed through the network between the monitored infrastructure and the logging layer.

 

The diagram shows how all data traffic (logs, metrics and events) are routed through the network between the monitored infrastructure and the logging layer.
Close Process Liveness
The next key metric is the liveness of the unified logging layer processes. A unified logging layer must have at least one point of aggregation for incoming logs and data that processes and distributes events to log management systems. A complete or partial failure of a log aggregator can prevent events from being received, processed and distributed to a management system.

Smaller log forwarder instances deployed on monitored nodes add robustness to the log and data collection process. Forwarders can buffer events should an aggregator become temporarily unavailable due to system reboot, process restart or temporary network connectivity failure. The loss of a forwarder instance means events from the monitored application or node cannot be collected by the aggregators.

NOTE: Log handlers must be online to collect and process data.

The diagram shows Fluentd acting as both the log forwarder deployed on each app, node, service and switch and the log aggregator, in the logging layer. If the Fluentd Forwarder on Node 1 dies, as indicated by the red cancel sign, then the logging layer has lost visibility into that node’s events.

 

Diagram showing Fluentd acting as both the log forwarder deployed on each app, node, service and switch and the log aggregator, in the logging layer

Close Host Resource Availability
Each log processor requires a certain amount of host resources to perform its job effectively. Ensuring that event processing and buffering operations have enough resources available to perform their tasks is key to having a healthy unified logging layer.

A robustly configured log processor requires storage (memory or local drive space, depending on its configuration) to store events in a buffer before delivery, which guards against data loss. For those instances, it is necessary to ensure memory and storage availability.

The actual event processing, like Fluentd filtering, parsing and compression, requires CPU processing power and threads to run workers on. This is especially true in high-traffic environments (which have message rates exceeding 5000 messages per second), where Fluentd is prone to becoming CPU bound due to limited CPU availability.

The example shell session below shows the top output of a Fluentd aggregator container. The container is running a pair of processes owned by the fluentd user, which are the processes managing Fluentd processing. The df output on the aggregator's buffer directory shows the overall filesystem footprint for this container.

/ # top

Mem: 1812816K used, 2216128K free, 20868K shrd, 132464K buff, 617220K cached
CPU:   0% usr   4% sys   0% nic  95% idle    0% io  0% irq 0% sirq
Load average: 0.04 0.06 0.05 4/493 36
  PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND
   17    6  fluent   S     105m   3%   1   0% {ruby} worker:aggregator1
    6    1  fluent   S    99.7m   3%   0   0% {fluentd} supervisor:aggregator1
   26    0  root     S     1592   0%   0   0% sh
   36   26  root     R     1524   0%   1   0% top
    1    0  root     S      200   0%   0   0% {entrypoint.sh} /usr/bin/dumb-init /bin/sh /bin/entrypoint.sh /bin/sh -c exec fluentd -c /fluentd

/ # ls -l /logs/aggregator1

total 8
-rw-r--r--    1 fluent   fluent            789 Apr 19 14:15 buffer.b586e2c0f0bcfbf0a953e571fd52c6304.log
-rw-r--r--    1 fluent   fluent            68 Apr 19 14:15 buffer.b586e2c0f0bcfbf0a953e571fd52c6304.log.meta

Close Overall Message Throughput
Finally, the overall message throughput is a key indicator of unified logging layer health.

The rate at which sources forward events provide a general indicator that all sources and log forwarders are healthy - a reduction in log/data input indicates a failure of either an application or logging layer component. Monitoring the overall message throughput helps ensure that events are being collected, processed and distributed in a timely manner.

Buffer sizes, buffer queues and buffer flush intervals are another indicator of message throughput. Large buffer sizes, long queues and delays in buffer flushes indicate a destination system is not responding.

The three diagrams illustrate scenarios where overall message throughput could act as an indicator of logging layer health.

The topmost diagram shows healthy, even throughput of incoming and outgoing events.

The second diagram shows a reduced stream of incoming events, illustrated by a single arrow going to the logging layer (represented by Fluentd), with the logging layer continuing to send events as normal. Such a condition could indicate that one or more source systems has stopped reporting, and thus, this scenario is labeled as a possible event source failure.

The third diagram shows a similar scenario, but for a destination. The stream of events going out of the logging layer towards consumers is reduced, with sources still reporting events normally. This could represented a possible failure in the logging layer itself or the destination, with the result being compromised event flow from the logging layer.

 

Three diagrams illustrating scenarios where overall message throughput could act as an indicator of logging layer health

How to Monitor Fluentd
The key Fluentd metrics discussed on the previous pages can be monitored in various ways.

Click on each box to learn about them.

How to Monitor Fluentd
Close Network Connectivity
Network connectivity is monitored by configuring Fluentd with a network-accessible plugin like in_http or in_forward. An external monitoring solution can then continuously monitor each Fluentd instance's network connectivity by pinging those network endpoints.

Close Process Liveness
Process liveness is monitored by tracking the Fluentd processes spawned at runtime. Tools like top or ps can check for the presence of all Fluentd Ruby processes, so a monitoring solution should have alarms in place to send alerts if any of those processes are lost. This process liveness status can also be established through successful network connectivity. However, a network failure or a process failure would compromise network-based checks without the ability to discriminate between the two cases. This may be an acceptable compromise for many.

Close Host Resource Availability
Using node-level monitoring tools like top or df to monitor CPU, memory and disk usage for any nodes where Fluentd is deployed allows monitoring solutions to keep track of whether Fluentd itself is using the correct amount of resources.

Close Message Throughput
Message throughput is monitored by configuring Fluentd with monitoring-specific plugins, like the Prometheus plugins providing open metrics endpoints which Prometheus can scrape at regular intervals, or the built-in monitoring and metrics agents included with Fluentd to expose metrics via the REST API.

The diagram represents a Fluentd instance that is configured to be monitored, showing that: network monitoring is possible using the forward or http plugins; the Prometheus plugin allows metrics to be scraped from Fluentd itself; and the host has several of the aforementioned tools available to retrieve data from.



Monitoring Fluentd with Prometheus
The officially recommended approach to monitoring Fluentd is to use Prometheus, a monitoring tool and time-series database that, like Fluentd, is one of several CNCF projects.

Prometheus can be configured to regularly gather metrics data from exposed network endpoints, a process called scraping. To expose Prometheus compatible endpoints, Fluentd should be configured to use Prometheus plugins that allow internal metrics like message throughput and output to be exposed in an open metrics format.

The presented diagram shows how the Prometheus plugin set exposes metrics. If set up as a filter, Prometheus is able to scape metrics on incoming events. When set up as an output, outgoing event metrics are exposed to a "/metrics" endpoint which Prometheus can scrape.

Setting up Fluentd monitoring with Prometheus will be explored in this chapter's lab exercise.

 



Configuring Prometheus Monitoring with Fluentd
The following shell session shows an example of Fluentd configured with Prometheus plugins. Here, Fluentd is configured with a pair of Prometheus sources to enable the /metrics endpoint (facilitated by the Prometheus source plugin) and to expose internal metrics about queue sizes, behaviors and retries (which are made available with the promethues_monitor plugin).

A <filter> directive is also configured in this file to expose a specific metric, fluentd_retrieved_status_codes_count, which is retrieved from an incoming event's message key.

An event with a message key paired with a random number value was sent to Fluentd and, when the /metrics endpoint was queried, you can see that the received count for fluentd_retrieved_status_codes_count reported 1.

$ cat prometheus-fluentd.conf

<source>
  @type prometheus
</source>
<source>
  @type prometheus_monitor
</source>
<source>
  @type forward
</source>
<filter mod8.*>
  @type prometheus
  <metric>
    name fluentd_retrieved_status_codes_count
    type histogram
    desc The total number of status code-bearing requests
    key message
  </metric>
</filter>
<match>
  @type file
  path /tmp/fluentd.monitored.log
</match>

$ echo '{"message":'$RANDOM'}' | fluent-cat mod8.prometheus

$ pkill -SIGUSR1 fluentd

$ curl -s localhost:24231/metrics | grep fluentd_retrieved_status_codes

# TYPE fluentd_retrieved_status_codes histogram
# HELP fluentd_retrieved_status_codes The total number of status code-bearing requests
...
fluentd_retrieved_status_codes_sum 13465.0
fluentd_retrieved_status_codes_count 1.0

Chapter Overview
Due to the importance of a platform’s logging layer, tuning and securing logging services is often a high priority.

This chapter will cover various configuration techniques that promote performance, stability, and security in Fluentd. These include logging adjustment for debugging and performance optimization on both the host and Fluentd configuration file.

This chapter will also cover other modes of operation for Fluentd, including multi-worker processing and TLS-secured communication for events.

The lab for this chapter will cover how to implement discussed debugging and performance tuning techniques.



Learning Objectives
By the end of this chapter, you should be able to:

Learn about the tools and procedures used for debugging Fluentd configurations.
Explore performance tuning techniques to optimize Fluentd deployments.
Learn how to secure Fluentd instance communications using TLS.

Debugging Configuration Files
If a configuration is incomplete or incorrect, Fluentd will generate an error on start-up along with details specifying the error and where it was encountered.

Fluentd ignores deprecated parameters, like buffer_type (which was a buffering-related parameter used directly within a <match> directive in Fluentd versions 0.12 and below). When deprecated parameters are provided, Fluentd attempts to use a modern equivalent. If that's successful, then Fluentd will start and run without issue; otherwise, Fluentd will exit with an error.

In both instances, keeping an eye on Fluentd's output is important to identify out of specification configuration files, which may or may not produce the desired behavior.

Error events that Fluentd generates after start-up can be captured and processed like any other event. If Fluentd receives an invalid event (one which cannot be parsed or is malformed) Fluentd generates a warning and sends the event to special labels. There are two built-in labels that will capture error events: @ERROR, which will handle any records that failed to process, and @FLUENT_LOG, which will capture Fluentd internal events. By exposing these two labels in a configuration file, Fluentd can report its own errors to users and consumers like it would do with any other event.

The example below shows how Fluentd informs the user of improper configuration file syntax, which prevents starting due to obvious user error. The error that was generated indicates that a <match> directive was not closed, causing Fluentd to fail to start.

$ fluentd -c fluentd-excessive-processing.conf

Traceback (most recent call last):
  14: from /usr/local/bin/fluentd:23:in `<main>'
  13: from /usr/local/bin/fluentd:23:in `load'
...
/var/lib/gems/2.7.0/gems/fluentd-1.12.2/lib/fluent/config/basic_parser.rb:92:in `parse_error!': expected end tag '</match>' but got end of file at excessive-processing.conf line 9,8 (Fluent::ConfigParseError)
  8: path /tmp/lab9/output.txt
  9: <match>
     --------^

@ERROR Label
@ERROR is a built-in label that is available to all plugins. Any error event produced by Fluentd plugins using the emit_error_event API is automatically directed to this label for further processing. Once redirected, the directives in the label can be set up to work like a dead letter queue to store unprocessed messages. This ensures that erroneous messages are not lost and can be examined by developers for later debugging or even processed by another processing pipeline.

To see messages and events sent to @ERROR, users only need to configure it like any other label: declare a <label @ERROR> directive at any point in the configuration file, then place a <filter> or <match> directive beneath that label.

The configuration example demonstrates the @ERROR label in action. The Fluentd instance is configured to parse incoming messages from the Fluentd socket as msgpack, then send it to a buffer to be output to a file. When the user sends a JSON event to the Fluentd instance, Fluentd generates a warning and outputs the event to the error file (a log prefixed with "fluentd.errors").

$ cat fluentd.conf

<source>
  @type forward
  port 32766
</source>
<filter mod.*>
  @type parser
  key_name "message"
  <parse>
    @type "msgpack"
  </parse>
</filter>
<match mod.*>
  @type file
  path "/tmp/app/logs/aggregate"
  <buffer time>
    path "/tmp/app/logs/aggregate"
  </buffer>
</match>
<match>
  @type null
</match>
<label @ERROR>
  <match>
    @type file
    path /tmp/fluentd.errors
  </match>
</label>

$ echo '{"message":"{\"mod6\":\"slide 11\"}"' | fluent-cat mod.6 -p 32766

$ pkill -sigusr1 fluentd

$ cat /tmp/fluentd.errors.202105075_0.log

2021-05-07T15:29:55+00:00 mod.6 {"message":"{\"mod6\":\"slide 11\"}"}

Logging Options
Users have the option to adjust the log verbosity and destination for the Fluentd instance.

Verbosity is changed in two ways: on the command line with switches, and by setting the @log_level parameter in the configuration file. Log levels set inside the configuration file can be declared globally for the instance, or on a per-plugin basis. Plugins will use the global log verbosity setting if no @log_level parameter is set at the plugin level.

Log verbosity can also be adjusted on the Fluentd command line. The @log_level supported values, in increasing order of verbosity are:

Fatal
Error (-qq on the commend line; very quiet)
Warn (-q; quiet)
Info (the default)
Debug (-v; verbose)
Trace (-vv; very verbose).
The <label @FLUENT_LOG> directive allows users to capture system-generated logs (which have the @FLUENT_LOG label attached to them), as events. Enabling the @FLUENT_LOG label also ensures that system-generated events are not captured by permissive <filter> or <match> directives.

Finally, Fluentd log output can be redirected at start-up by supplying the -o flag with a path to the intended file.

The example below shows log verbosity being set to very verbose, with the first instance launching with default verbosity and the second instance launching with [trace] verbosity using the -vv flag.

$ fluentd -c fluentd-light.conf

2021-05-07 15:37:12 +0000 [info]: parsing config file is succeeded path="atfluent.conf"
2021-05-07 15:37:12 +0000 [info]: gem 'fluentd' version '1.12.2'
2021-05-07 15:37:12 +0000 [info]: using configuration file: <ROOT>
...
2021-05-07 15:37:13.612007230 +0000 fluent.info: {"worker":0,"message":"fluentd worker is now running worker=0"}

$ fluentd -c fluentd-light.conf -vv

2021-05-07 15:37:19 +0000 [info]: fluent/log.rb:329:info: parsing config file is succeeded path="atfluent.conf"
2021-05-07 15:37:19 +0000 [info]: fluent/log.rb:329:info: gem 'fluentd' version '1.12.2'
2021-05-07 15:37:19 +0000 [trace]: fluent/log.rb:286:trace: registered output plugin 'stdout'
2021-05-07 15:37:19 +0000 [trace]: fluent/log.rb:286:trace: registered buffer plugin 'memory'
2021-05-07 15:37:19 +0000 [trace]: fluent/log.rb:286:trace: registered formatter plugin 'stdout'
2021-05-07 15:37:19 +0000 [trace]: fluent/log.rb:286:trace: registered formatter plugin 'json'
2021-05-07 15:37:20 +0000 [trace]: fluent/log.rb:286:trace: registered input plugin 'forward'
2021-05-07 15:37:20 +0000 [info]: fluent/log.rb:329:info: using configuration file: <ROOT>
...
2021-05-07 15:37:20.641278352 +0000 fluent.info: {"worker":0,"message":"fluentd worker is now running worker=0"}
@FLUENT_LOG Label
In this example, Fluentd is configured to expose the @FLUENT_LOG built-in label, which captures Fluentd internal log messages and outputs them as normal Fluentd events. Like any other label, it can contain <filter> and <match> directives to route the captured Fluentd events to an appropriate destination. In this configuration, any Fluentd events captured will have a host key with the hostname value appended to the event's record.

This configuration is run with the stdout output of Fluentd is routed to /tmp/fluentd/fluentd.forwarder.output.log with the -o flag.

Using cat on the log to read it, you can see that it captured a fluent.debug event, which is not normally visible at lower log verbosity levels.

$ cat file-forwarder.conf

<system>
  process_name forwarder
</system>
<source>
  @type tail
  path /tmp/app.log
  pos_file /tmp/app.log.pos
  tag my.application
<parse>
  @type none
</parse>
</source>
<match>
  @type forward
  <server>
    name aggregator1
    host 172.17.0.2
    port 24500
    weight 50
  </server>
</match>
<label @FLUENT_LOG>
  <filter fluent.*>
        @type record_transformer
        <record>
        host "#{Socket.gethostname}"
        </record>
  </filter>
  <match fluent.*>
        @type stdout
  </match>
</label>

$ fluentd -c file-forwarder.conf -d 9999 -o fluentd.stdout

$ tail fluentd.stdout

2021-05-07 15:40:26 +0000 [info]: #0 fluentd worker is now running worker=0
2021-05-07 15:40:26.635642038 +0000 fluent.info: {"pid":1904,"ppid":1901,"worker":0,"message":"starting fluentd worker pid=1904 ppid=1901 worker=0","host":"labsys"}
2021-05-07 15:40:26.636530552 +0000 fluent.info: {"worker":0,"message":"fluentd worker is now running worker=0","host":"labsys"}

Performance Tuning Considerations
There are several performance tuning techniques that can be applied to a Fluentd instance.

First, there are host-side optimizations that can be performed:

Optimize the OS before installing Fluentd (recommended pre-installation steps)
Of importance is ensuring that Fluentd cannot run out of file descriptors and optimizing the network kernel parameters of the host. These optimizations are covered in Lab 1-A, where they are presented as pre-installation steps.
Configure the Ruby garbage collector via environment variables
Another host-side optimization is configuring Ruby to lower memory usage, specifically by tuning Ruby garbage collection (GC) to control memory growth and usage. Lowering the value for the RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR variable (default: 2) ensures that old objects are flushed more regularly to keep memory usage down. Other environment variables like: RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR, RUBY_GC_MALLOC_LIMIT, RUBY_GC_MALLOC_LIMIT_MAX, and RUBY_GC_MALLOC_LIMIT_GROWTH_FACTOR also affect how often Ruby's minor (GC_MALLOC) and major (GC_OLDMALLOC) garbage collections occur.
You can see more in the Ruby source code (written in C).

A way to configure these will be demonstrated in the next example.

However, tuning the host OS might not be enough, especially in larger Fluentd deployments. There are a few configuration-file side performance tuning measures that can be taken in addition to the host-side measures:

Minimizing the amount of plugins keeps configurations lean. This reduces the Fluentd resource footprint and minimizes processing overhead, which is especially important for Fluentd instances that are deployed alongside the applications they monitor. More expensive processing tasks can be relocated to aggregator nodes.
Intensive tasks, like compression, can cause Ruby to become a bottleneck for a Fluentd instance due to Ruby's global interpreter lock (called "Global VM Lock" in Ruby), which prevents smaller jobs from running when a long running job is in progress. Plugins that use compression will often provide parameters that can offload compression tasks to an external tool like gzip. This ensures that Ruby itself is free to process other tasks.
Fluentd can be tuned to use more CPU by setting configuration parameters like: flush_threads_count to utilize more threads (by parallelizing output plugin flush operations) and workers to spawn additional Fluentd workers to distribute event processing.​

Ruby Tuning Example
The following example shows two Fluentd containers under the same workload but with different Ruby tunings. The first container, aggregator1, is set to perform Ruby garbage collection more often by setting the following environment variables:

RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR=0.1
RUBY_GC_MALLOC_LIMIT_GROWTH_FACTOR=1.1
RUBY_GC_MALLOC_LIMIT_MAX=16000100
RUBY_GC_MALLOC_LIMIT=4000100
RUBY_GC_OLDMALLOC_LIMIT=16000100
RUBY_GC_OLDMALLOC_LIMIT_MAX=4000100
Another Fluentd instance, aggregator2, is run with no adjustments.

When put under the same workload using the fluent-cat tool to feed messages to both instances, checking the output of top in each contain shows that aggregator1 is able to maintain a slightly lower memory use value compared to aggregator2. The aggregator1 instance is performing garbage collection more frequently and thus maintains a gap between it and aggregator2.

$ sudo docker run -p 24500:24500 --name aggregator1 -d -v $HOME/aggregator1:/fluentd/etc -v /tmp/logs:/logs -e

FLUENTD_CONF=aggregator*.conf -e RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR=0.1 -e RUBY_GC_MALLOC_LIMIT_GROWTH_FACTOR=1.1 -e RUBY_GC_MALLOC_LIMIT_MAX=16000100 -e RUBY_GC_MALLOC_LIMIT=4000100 -e RUBY_GC_OLDMALLOC_LIMIT=16000100 -e RUBY_GC_OLDMALLOC_LIMIT_MAX=4000100 fluent/fluentd:v1.12.2-1.0 fluentd -c /fluentd/etc/aggregator1.conf b2b24058bfea846bbd6868a6ede91a50fb982b56daa8fb25edfa15cf6fb8c932

$ sudo docker run -p 25500:25500 --name aggregator2 -d -v $HOME/aggregator2:/fluentd/etc -v /tmp/logs:/logs -e

FLUENTD_CONF=aggregator*.conf fluent/fluentd:v1.12.2-1.0 153cfe951ca21bb45cbb3e2b3e5fb64dd4da372c445541c17c135bd578487974

$ while true; do echo '{"lfs242":"learn"}' | fluent-cat mod9.slides --port 24500; done & [1] 6660

$ while true; do echo '{"lfs242":"learn"}' | fluent-cat mod9.slides --port 25500; done & [2] 6727

$ sudo docker container exec aggregator1 top

Mem: 1153176K used, 2816308K free, 932K shrd, 57540K buff, 591760K cached
CPU:  78% usr  21% sys   0% nic   0% idle   0% io   0% irq   0% sirq
Load average: 0.86 0.34 0.13 4/272 25
  PID  PPID USER      STAT   VSZ %VSZ CPU %CPU COMMAND
   16  7 fluent S        100m   3%   0   0% {ruby} worker:aggregator1
    7  1 fluent S       98.7m   3%   0   0% {fluentd} supervisor:aggregator1
   19  0 fluent R        1576   0%   1   0% top
    1  0 fluent S         776   0%   1   0% tini -- /bin/entrypoint.sh fluentd

$ sudo docker container exec aggregator2 top

Mem: 1158004K used, 2811480K free, 940K shrd, 57548K buff, 591788K cached
CPU:  85% usr  15% sys   0% nic   0% idle   0% io   0% irq   0% sirq
Load average: 1.31 0.50 0.19 4/274 25
  PID  PPID USER      STAT   VSZ %VSZ CPU %CPU COMMAND
   16  7 fluent S        103m   3%   0   0% {ruby} worker:aggregator2
    7  1 fluent S       99.7m   3%   0   0% {fluentd} supervisor:aggregator2
   19  0 fluent R        1576   0%   0   0% top
    1  0 fluent S         776   0%   0   0% tini -- /bin/entrypoint.sh fluentd

Multi-Process Workers
Fluentd can be configured to run with multiple processes to handle larger event loads if the worker parameter is declared under the <system> directive. Each of these workers is capable of executing any of the processing pipelines in a given Fluentd configuration. These workers receive events from a supervisor process, which receives all traffic and also system signals that affect the life of each worker.

Fluentd always spawns a supervisor and one worker process. By specifying the worker parameter, Fluentd is informed to start another worker process. By splitting event processing pipelines to multiple workers, an instance of Fluentd can be configured to handle more events.

A worker process executes input, filter and output plugins.

The following diagram illustrates a multi-worker process:

Multi-Process Worker Configuration
To configure additional worker processes, the worker parameter needs to be specified under the <system> directive with an integer. The integer provided determines how many processes (starting from 0) are spawned when the Fluentd instance is run.

Individual or sets of workers can be configured to handle specific pipelines by declaring a series of <worker N> root directives, where N is an integer declaring a specific worker, or N-M declaring a range of workers. Under each <worker> root directive, event processing pipelines are configured as previously shown throughout this course.

Multi-worker support varies between plugins and is plugin-dependent:

Input plugins that open ports, like forward or monitor_agent, have a different behavior. The forward plugin allows all workers to share a configured port. When a multi-worker instance of Fluentd is started with the forward plugin, each worker will listen on the same port. The diagram shows that workers 0 and 1 are using the same configuration. Since both are using in_forward, they will both accept traffic from the same port opened by in_forward. Other plugins, like monitor_agent, use the configured port as a starting value that is incremented up with each additional worker (worker 0 would use 24500, worker 1 would use port 24501 and so on).
There are plugins that do not support multi-worker instances, like tail. Those plugins must be configured to run under a specific worker. This is shown in the diagram in Worker 2.
Finally, plugins that write to files or use buffering must be configured to use separate directories per worker. Preventing multiple workers from writing to the same buffer and file paths avoids the issue of data loss caused by uncontrolled overwriting.

Multi-Worker Log Aggregator
In the following example, a Fluentd log aggregator is configured to run three different workers. No other worker directives have been declared in this configuration, so all tasks are distributed evenly among the workers.

When this configuration is run, Fluentd spawns four processes: one supervisor and three workers. The supervisor opens the incoming sockets, in this case port 24500, for incoming Fluentd events, and then distributes the events to each of the workers.

~/aggregator1$ cat aggregator1.conf

<system>
  process_name aggregator1
  workers 3
</system>
<source>
  @type forward
  port 24500
</source>
<match>
  @type stdout
</match>

~/aggregator1$ sudo docker run -d -p 24500:24500 --name aggregator1 -v $HOME/aggregator1:/fluentd/etc -v /tmp/logs:/logs -e FLUENTD_CONF=aggregator*.conf fluent/fluentd:v1.12.2-1.0 fluentd -c /fluentd/etc/aggregator1.conf

cee6fbf98691afed39ce06f34371411bfac30fe5b132f597dd7941969880f77a

~/aggregator1$ sudo docker logs aggregator1

...
2021-05-07 17:31:42 +0000 [info]: #0 starting fluentd worker pid=17 ppid=8 worker=0
2021-05-07 17:31:42 +0000 [info]: #0 listening port port=24500 bind="0.0.0.0"
2021-05-07 17:31:42 +0000 [info]: #0 fluentd worker is now running worker=0
2021-05-07 17:31:42.341964635 +0000 fluent.info: {"pid":17,"ppid":8,"worker":0,"message":"starting fluentd worker pid=17 ppid=8 worker=0"}
2021-05-07 17:31:42.343008194 +0000 fluent.info: {"port":24500,"bind":"0.0.0.0","message":"listening port port=24500 bind=\"0.0.0.0\""}
2021-05-07 17:31:42.351876681 +0000 fluent.info: {"worker":0,"message":"fluentd worker is now running worker=0"}
2021-05-07 17:31:42 +0000 [info]: #2 starting fluentd worker pid=19 ppid=8 worker=2
2021-05-07 17:31:42 +0000 [info]: #2 listening port port=24500 bind="0.0.0.0"
2021-05-07 17:31:42 +0000 [info]: #2 fluentd worker is now running worker=2
2021-05-07 17:31:42.487625393 +0000 fluent.info: {"pid":19,"ppid":8,"worker":2,"message":"starting fluentd worker pid=19 ppid=8 worker=2"}
2021-05-07 17:31:42.488753880 +0000 fluent.info: {"port":24500,"bind":"0.0.0.0","message":"listening port port=24500 bind=\"0.0.0.0\""}
2021-05-07 17:31:42.490093040 +0000 fluent.info: {"worker":2,"message":"fluentd worker is now running worker=2"}
2021-05-07 17:31:42 +0000 [info]: #1 starting fluentd worker pid=18 ppid=8 worker=1
2021-05-07 17:31:42 +0000 [info]: #1 listening port port=24500 bind="0.0.0.0"
2021-05-07 17:31:42 +0000 [info]: #1 fluentd worker is now running worker=1

~/aggregator1$ sudo docker container exec aggregator1 ps

PID   USER    TIME  COMMAND
    1 fluent  0:00 tini -- /bin/entrypoint.sh fluentd -c /fluentd/etc/aggregator1.conf
    8 fluent  0:00 {fluentd} supervisor:aggregator1
   17 fluent  0:01 {ruby} worker:aggregator10
   18 fluent  0:01 {ruby} worker:aggregator11
   19 fluent  0:01 {ruby} worker:aggregator12
   26 fluent  0:00 ps

Multi-Worker Log Forwarder
In the example below, a log forwarder is configured to run on more than one worker. It is also set up to send its output plugin buffers to /tmp/fluentd/buffer.

If only the workers 2 parameter is provided with no other configuration, Fluentd will fail to start. This is because the plugin this log forwarder is configured with, in_tail, does not support multiple processes.

To remedy this, the configuration needs to nest the tail plugin, and any other plugin pipelines that do not support multi-process workers, beneath a <worker #> directive. This directive specifies that any nested plugins and processing pipelines are run only on the specified worker. Once the tail pipeline is nested beneath a <worker> directive, in this case <worker 0>, it is restricted to run only on worker 0 and Fluentd is able to start. Even though only one worker was configured with a processing pipeline, Fluentd still respected the workers 2 parameter and spawned an additional worker process.

Once Fluentd has started, a buffer folder at /tmp/fluentd/buffer has been created. Each worker will store its output plugin buffers in this folder. This avoids having multiple workers overwrite each other's buffers, which can cause data loss.

~/forwarder$ cat file-forwarder.conf

<system>
  process_name forwarder
  workers 2
  root_dir /tmp/fluentd/buffer
</system>
<source>
  @type tail
  path /tmp/app.log
  pos_file /tmp/app.log.pos
  tag my.application
  <parse>
    @type none
  </parse>
</source>
<match>
  @type forward
<server>
   name aggregator1
   host 172.17.0.2
   port 24500
   weight 50
 </server>
</match>

~/forwarder$ fluentd -c file-forwarder.conf -v

...
2021-05-07 17:37:22 +0000 [error]: #1 fluent/log.rb:371:error: config error file="file-forwarder.conf" error_class=Fluent::ConfigError error="Plugin 'tail' does not support multi workers configuration (Fluent::Plugin::TailInput)"=

~/forwarder$ cat file-forwarder.conf

<system>
  process_name forwarder
  workers 2
  root_dir /tmp/fluentd/buffer
</system>
<worker 0>
  <source>
    @type tail
    ...
</worker>

~/forwarder$ fluentd -c file-forwarder.conf -o /tmp/fluentd/fluentd.forwarder.output.log &

~/forwarder$ cat /tmp/fluentd/fluentd.forwarder.output.log

...
2021-05-07 17:40:03 +0000 [info]: #1 starting fluentd worker pid=10631 ppid=10627 worker=1
...
2021-05-07 17:40:03 +0000 [info]: #0 fluentd worker is now running worker=0

$ ls -l /tmp/fluentd/

total 8
drwxr-xr-x 2 ubuntu ubuntu 4096 May 7 17:37 buffer
-rw-rw-r-- 1 ubuntu ubuntu 2108 May 7 17:40 fluentd.forwarder.output.log

TLS/SSL in Multi-Instance Deployments
Starting in Fluentd version 0.14, many TLS functions were improved and merged into the in_forward and out_forward plugins. A user can set up TLS to secure communications between two Fluentd instances by providing the plugins with valid certificates. Other plugins can use TLS functionality by using the server or http_server plugin helper.

To set up TLS secure communications, a log aggregator must be configured with the <transport tls> subdirective under a <source> directive using the in_forward plugin.

Click on each box to learn about TLS modes supported by Fluentd. 

TLS Modes
Close Privacy
Once the log aggregator is started with TLS options, any log forwarders that need to connect to it must be able to verify the log aggregator's certificate. This can be done with a self-signed certificate generated by the log aggregator.

Close Server Authentication
A certificate from a public or private Certificate Authority (CA) can also be used to authenticate certificates for one-way server or mutual authentication. In one-way server authentication, the log aggregator sends its certificates to the log forwarder, which authenticates the incoming certificate against a trusted CA certificate.

Close Mutual Authentication
TLS with mutual authentication can be configured by enabling client certificate authentication on the log aggregator. In this configuration, a log forwarder must send back a certificate to the log aggregator, which authenticates against a mutually trusted CA certificate. A connection is established if both the log aggregator and log forwarder accept each other's certificates.

Configuration examples for each of the TLS modes will be shown in the following examples.



TLS with Self-Signed Certificates (Privacy)
The example below shows TLS configurations for privacy between a log aggregator and log forwarder using a self-signed certificate from the log aggregator. In this setup, no CA is involved in authenticating the certificates.

The out_forward plugin is configured under the log forwarder's <match> directive to provide a path to the log aggregator's self-signed certificate. Since a self-signed certificate is being used, the tls_allow_self_signed_cert true parameter is necessary to ensure the forwarder accepts the certificate.

The log aggregator's certificate includes the hostname. Since it is running in a Docker container, the tls_verify_hostname false parameter is provided to ensure that there are no rejections based on the server hostname failing to match the reverse DNS for the server’s IP.

If the log forwarder is able to successfully decrypt the certificate and establish a connection, events are sent to the log aggregator as normal.

$ cat ~/aggregator1/self-tls.conf

<system>
  process_name aggregator1
</system>
<source>
  @type forward
  port 24500
  <transport tls>
    cert_path /fluentd/etc/aggregator1-self.crt
    private_key_path /fluentd/etc/aggregator1-self.key
    private_key_passphrase "#{ENV['PASSPHRASE']}"
  </transport>
</source>
<match>
  @type stdout
</match>

$ cat ~/forwarder/tls-self-server-auth.conf

<system>
  process_name forwarder
</system>
<source>
  @type forward
  port 32767
</source>
<match>
  @type forward
  transport tls
  tls_cert_path /home/ubuntu/forwarder/aggregator1-self.crt
  tls_allow_self_signed_cert true
  tls_verify_hostname false
  <server>
    name aggregator1
    host 172.17.0.2
    port 24500
  </server>
</match>

TLS Server Authentication: Log Aggregator Configuration
This example shows a Fluentd log aggregator configured to use TLS server authentication, where the log aggregator submits its certificate to the log forwarder. The log forwarder then authenticates the log aggregator's certificate against a trusted CA certificate. To establish a connection, the log aggregator certificate must bear a signature matching the CA certificate present on the log forwarder.

The <source> directive of server-auth.conf is configured to use @type forward to enable other Fluentd instances to communicate with it.

The <transport tls> subdirective provides a path to the certificate (cert_path) and private key file (private_key_path). A passphrase for the private key, if one was provided to the certificate file, must also be provided with private_key_passphrase. In this case, the passphrase is supplied by an environment variable (provided to the container with the -e environment variable switch). Equivalent settings for the signing certificate authority (CA) cert are also provided in this section if the certificate used is generated using a private CA.

Any log forwarders that connect to this log aggregator will do so using TLS, but the log aggregator will not require any certificates from them. We will examine the forwarder TLS configuration on the next page.

~/aggregator1$ cat server-auth.conf

<system>
  process_name aggregator1
</system>
<source>
  @type forward
  port 24500
  <transport tls>
      cert_path /fluentd/etc/aggregator1.pem
      private_key_path /fluentd/etc/aggregator1.key.pem
      private_key_passphrase "#{ENV['PASSPHRASE']}"
      ca_cert_path /fluentd/etc/fluentd-ca.pem
      ca_private_key_path /fluentd/etc/fluentd-ca.key.pem
      ca_private_key_passphrase "#{ENV['PASSPHRASE']}"
  </transport>
</source>
<match>
  @type stdout
</match>

~/aggregator1$ sudo docker run -p 24500:24500 --name aggregator1 -v $HOME/aggregator1:/fluentd/etc -v /tmp/logs:/logs -e PASSPHRASE=fluentd -e FLUENTD_CONF=ca-tls-server-auth.conf -d fluent/fluentd:v1.12.2-1.0 fluentd -c /fluentd/etc/server-auth.conf -vv

...
~/aggregator1$ sudo docker logs aggregator1
2021-05-07 20:23:54 +0000 [info]: #0 fluent/log.rb:329:info: starting fluentd worker pid=16 ppid=7 worker=0
2021-05-07 20:23:54 +0000 [info]: #0 fluent/log.rb:329:info: listening port port=24500 bind="0.0.0.0"
2021-05-07 20:23:54 +0000 [info]: #0 fluent/log.rb:329:info: fluentd worker is now running worker=0
2021-05-07 20:23:54.911906481 +0000 fluent.info: {"pid":16,"ppid":7,"worker":0,"message":"starting fluentd worker pid=16 ppid=7 worker=0"}
2021-05-07 20:23:54.912766281 +0000 fluent.info: {"port":24500,"bind":"0.0.0.0","message":"listening port port=24500 bind=\"0.0.0.0\""}
2021-05-07 20:23:54.914016641 +0000 fluent.info: {"worker":0,"message":"fluentd worker is now running worker=0"}

TLS Server Authentication: Log Forwarder Configuration
The example below shows a log forwarder configured to send events to the TLS-secured log aggregator in a server authentication configuration. Only the client (log forwarder) verifies the log aggregator's certificate. The certificate sent from the log aggregator must bear a signature that matches the CA certificate to connect.

The out_forward plugin is configured under the log forwarder's <match> directive, which declares the transport tls parameter to send events to the log aggregator using TLS. The tls_cert_path parameter is declared to provide the path to a CA certificate file (found under /home/ubuntu/tls-ca/ca.crt) to authenticate against the log aggregator's certificate. The tls_verify_hostname parameter allows the client to omit hostname verification during the TLS transaction if not needed.

If the log forwarder is able to connect, events are sent to the log aggregator as normal. Messages regarding TLS authentication's presence in the configuration are only printed only if the log forwarder is started with trace verbosity.

~/forwarder$ cat ~/forwarder/tls-server-auth.conf

<system>
  process_name forwarder
</system>
<source>
  @type forward
  port 32767
</source>
<match>
  @type forward
  transport tls
  tls_cert_path /home/ubuntu/tls-ca/fluentd-ca.pem
  tls_verify_hostname false
  <server>
    name aggregator1
    host 172.17.0.2
    port 24500
  </server>
</match>

~/forwarder$ fluentd -c tls-server-auth.conf -vv

...
2021-05-07 20:38:08 +0000 [info]: #0 fluent/log.rb:329:info: fluentd worker is now running worker=0
...
2021-05-07 20:38:09 +0000 [debug]: #0 fluent/log.rb:308:debug: connect new socket
2021-05-07 20:38:09 +0000 [trace]: #0 fluent/log.rb:286:trace: writing events into buffer instance=1780 metadata_size=1
2021-05-07 20:38:09 +0000 [trace]: #0 fluent/log.rb:286:trace: loading system default certificate store
2021-05-07 20:38:09 +0000 [trace]: #0 fluent/log.rb:286:trace: writing events into buffer instance=1780 metadata_size=1
2021-05-07 20:38:09 +0000 [trace]: #0 fluent/log.rb:286:trace: adding CA cert path="/home/ubuntu/tls-ca/fluentd-ca.pem"
2021-05-07 20:38:09 +0000 [trace]: #0 fluent/log.rb:286:trace: writing events into buffer instance=1780 metadata_size=1
2021-05-07 20:38:09 +0000 [trace]: #0 fluent/log.rb:286:trace: setting TLS context mode="peer" ciphers="ALL:!aNULL:!eNULL:!SSLv2"
2021-05-07 20:38:09 +0000 [trace]: #0 fluent/log.rb:286:trace: writing events into buffer instance=1780 metadata_size=1
2021-05-07 20:38:09 +0000 [trace]: #0 fluent/log.rb:286:trace: entering TLS handshake
2021-05-07 20:38:09 +0000 [trace]: #0 fluent/log.rb:286:trace: writing events into buffer instance=1780 metadata_size=1

TLS Mutual Authentication
This example shows a mutual authentication TLS configuration, where both the log aggregator and the log forwarder must provide valid, signed certificates to each other before connecting. Each log aggregator and log forwarder certificate is then authenticated against a mutually trusted CA certificate found on both hosts.

To configure this, the log aggregator sets client_cert_auth true; the default is false, meaning any client can connect without providing certificates. The ca_path parameter specifies what CA certificate to use when authenticating log forwarder client certificates.

The log forwarder in this configuration retains the tls_cert_path parameter from the server authentication configuration, pointing to the mutually trusted CA certificate. It also includes parameters that define its own certificate (tls_client_cert_path) and private key files (tls_client_private_key_path and tls_client_private_key_passphrase), which are sent to the log aggregator.

All of the certificates sent in this exchange must bear the same signature found on a mutually trusted CA certificate in order to maintain a connection. In this configuration, both the aggregator and the forwarder use the same ca.crt file to verify each other's certificates.

$ cat mutual-tls.conf

<system>
  process_name aggregator1
</system>
<source>
  @type forward
  port 24500
  <transport tls>
    cert_path /fluentd/etc/aggregator1.pem
    private_key_path /fluentd/etc/aggregator1.key.pem
    private_key_passphrase "#{ENV['PASSPHRASE']}"
    ca_cert_path /fluentd/etc/fluentd-ca.pem
    ca_private_key_path /fluentd/etc/fluentd-ca.key.pem
    ca_private_key_passphrase "#{ENV['PASSPHRASE']}"
    client_cert_auth true
  </transport>
</source>
<match>
  @type stdout
</match>

$ cat ~/forwarder/tls-mutual-auth.conf

<system>
  process_name forwarder
</system>
<source>
  @type forward
  port 32767
</source>
<match>
  @type forward
  transport tls
  tls_cert_path /home/ubuntu/tls-ca/fluentd-ca.pem
  tls_verify_hostname false
  tls_client_cert_path /home/ubuntu/forwarder/tls-forwarder.crt
  tls_client_private_key_path /home/ubuntu/forwarder/tls-forwarder.key
  tls_client_private_key_passphrase "#{ENV['FORWARDER_PASSPHRASE']}"
  <server>
    name aggregator1
    host 172.17.0.2
    port 24500
  </server>
</match>

Chapter Overview
Up to this point, we have explored ways in which Fluentd can be configured as both a log forwarder and a log aggregator. We have also discussed the benefits of maintaining a lightweight forwarding solution on systems where production applications run.

Fluent Bit is a logical extension of the lightweight Fluentd forwarder configurations we have examined in previous chapters. Fluent Bit is an extremely lightweight solution for collecting and distributing logs. In comparison to Fluentd, Fluent Bit trades Fluentd's broad set of features and plugins for a narrow focus with high performance and a small resource footprint.

This chapter will introduce Fluent Bit, discuss the similarities and differences between it and Fluentd, and demonstrate how the two can work together to provide a highly optimized unified logging solution.


Learning Objectives
By the end of this chapter, you should be able to:

Understand the purpose of Fluent Bit.
Contrast Fluent Bit and Fluentd.
Explain how Fluent Bit and Fluentd work together in various log processing scenarios.

What Is Fluent Bit?
Fluent Bit is a fast, lightweight, open source data processor and forwarder which allows you to collect data/logs from different sources, and unify and send them to multiple destinations.

It is intended for use on Linux, OSX, and BSD operating system families, and on x86_64, x86 and ARM-based devices. Deployments that have limited capacity and/or resource constraints, such as those using containers or IoT devices, are a perfect fit for Fluent Bit.

Fluent Bit differs from Fluentd in that it is written entirely in C and it lacks the log aggregation capabilities that Fluentd possesses. In exchange, Fluent Bit gains a smaller memory footprint and no external dependencies. It also comes pre-packaged with metrics collection capabilities.

Fluent Bit can work in tandem with Fluentd in a log processing pipeline - operating where Fluentd’s larger resource footprint may not be appropriate, forwarding events to a Fluentd aggregator.

Like Fluentd, Fluent Bit uses plugins to receive, parse, filter, buffer and output collected data to other sources. There are far fewer plugins available for Fluent Bit at present (as of August 2021).

Fluentd vs. Fluent Bit
The following table compares Fluentd and Fluent Bit (as of August 2021).

 

​CHARACTERISTICS	FLUENTD​	FLUENT BIT
Scope	Containers/Servers	C​ontainers/Servers
Language​	C and Ruby​	C
Memory​	~40MB​	​~450KB
Performance​	High performance​	Very high performance​
Dependencies​	Ruby, gems and several Ruby gems	Zero dependencies, unless some special plugin requires them
Plugins	More than 1000 plugins available	Over 80 plugins available​

Fluent Bit Configuration Schema Differences
Fluent Bit uses a slightly different configuration syntax than Fluentd, though it follows the same general format.

System, input, filter and output configurations are split into separate sections, under which specific plugins are configured to receive, process and distribute data. These sections are enclosed within square brackets, as opposed to the XML-like tags from Fluentd:

[SERVICE]
It sets global configuration for the instance, equivalent to the <system> directive.
[INPUT]
It configures input sources, equivalent to the <source> directive.
[FILTER]
It configures event processing, equivalent to the <filter> directive.
[OUTPUT]
It configures event delivery, equivalent to the <match> directive.
Under each section, parameters known as Entries are declared. Plugins are selected using the Name key (rather than @type) under the [INPUT], [FILTER], and [OUTPUT] sections. Keys may be capitalized, though that is not a strict requirement. For keys to be recognized, they must be indented (four spaces by convention) under the section they are declared.

Fluent Bit [FILTER] and [OUTPUT] sections do not incorporate the tag match pattern inside their section heading, as their equivalent would in Fluentd. To set the match pattern for a [FILTER] or [OUTPUT] section, the Match key must be declared. For regex pattern matching, the Match_Regex key can be used.

The @include directive can be used to reuse other Fluent Bit configurations, and works identically to Fluentd's @include functionality.

The configurations presented below show functionally identical Fluent Bit and Fluentd forwarder configurations.

$ cat fluent-bit-forwarder.conf

[SERVICE]
    Daemon off
    Log_Level info
    Flush 5

[INPUT]
    Name    tail
    Path    /tmp/log/app.log
    Tag     fluent.bit.app

[OUTPUT]
    Name    forward
    Port    24500
    Match   **

$ cat fluentd-fowarder.conf

<source>
  @type tail
  path /tmp/log/app.log
  <parse>
    @type none
  </parse>
  tag fluentd.app
</source>   

<match **>
  @type forward
  port 24500
</match>

Running Fluent Bit
Once built and installed on a system, Fluent Bit can be run in several ways.

First, it can be run like a Fluentd instance would: as a process (that can be daemonized) using a configuration file, loaded with the -c flag. Like any other Fluentd instance (or program, for that matter), it will take control of that terminal session and output its current status or any events to stdout (depending on configuration). This is the officially recommended way of running Fluent Bit.

A configuration file can be built-in to a Fluent Bit binary by specifying the FLB_STATIC_CONF option at build time with a path to a configuration file. Once built, running the Fluent Bit binary will result in a pre-configured instance. This can be used to further reduce the footprint of a Fluent Bit instance on a resource constrained system.

Fluent Bit can be run with -i, -o, and other flags to allow users to specify input and output plugins. The following example shows Fluent Bit being run with the -c option declaring a configuration file to load.

$ fluent-bit -c forwarder.conf

* Copyright (C) 2019-2021 The Fluent Bit Authors
* Copyright (C) 2015-2018 Treasure Data
* Fluent Bit is a CNCF sub-project under the umbrella of Fluentd
* https://fluentbit.io
[2021/05/07 23:38:43] [ info] [engine] started (pid=1956)
[2021/05/07 23:38:43] [ info] [storage] version=1.1.1, initializing...
[2021/05/07 23:38:43] [ info] [storage] in-memory
[2021/05/07 23:38:43] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128
[2021/05/07 23:38:43] [ info] [sp] stream processor started
Built-In Metrics Reporting
Fluent Bit comes with a selection of input plugins that can pull host metrics such as CPU, memory and disk usage.

It can also monitor network traffic, giving users visibility into overall throughput through a host's network devices.

Finally, it can issue continual heartbeat requests to TCP servers and system processes to track liveness and overall health for those pinged systems.

In this example, Fluent Bit is run with the cpu input plugin, which polls Linux at a configured interval for full system and per-core CPU usage.

$ fluent-bit -i cpu -t my_cpu -o stdout -m '*'

Fluent Bit v1.7.3
* Copyright (C) 2019-2021 The Fluent Bit Authors
* Copyright (C) 2015-2018 Treasure Data
* Fluent Bit is a CNCF sub-project under the umbrella of Fluentd
* https://fluentbit.io
[2021/05/07 23:40:26] [ info] [engine] started (pid=1962)
[2021/05/07 23:40:26] [ info] [storage] version=1.1.1, initializing...
[2021/05/07 23:40:26] [ info] [storage] in-memory
[2021/05/07 23:40:26] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128
[2021/05/07 23:40:26] [ info] [sp] stream processor started
[0] my_cpu: [1620430827.371237097, {"cpu_p"=>0.500000, "user_p"=>0.500000, "system_p"=>0.000000, "cpu0.p_cpu"=>1.000000, "cpu0.p_user"=>1.000000, "cpu0.p_system"=>0.000000, "cpu1.p_cpu"=>1.000000, "cpu1.p_user"=>1.000000, "cpu1.p_system"=>0.000000}]
[1] my_cpu: [1620430828.371225241, {"cpu_p"=>0.000000, "user_p"=>0.000000, "system_p"=>0.000000, "cpu0.p_cpu"=>0.000000, "cpu0.p_user"=>0.000000, "cpu0.p_system"=>0.000000, "cpu1.p_cpu"=>0.000000, "cpu1.p_user"=>0.000000, "cpu1.p_system"=>0.000000}]
[2] my_cpu: [1620430829.371286269, {"cpu_p"=>0.000000, "user_p"=>0.000000, "system_p"=>0.000000, "cpu0.p_cpu"=>0.000000, "cpu0.p_user"=>0.000000, "cpu0.p_system"=>0.000000, "cpu1.p_cpu"=>0.000000, "cpu1.p_user"=>0.000000, "cpu1.p_system"=>0.000000}]

Fluent Bit with Fluentd
Fluent Bit can interact with Fluentd using its out_forward plugin, submitting events through the Fluentd socket to other Fluent Bit or Fluentd instances.

In this example, a Fluentd instance is configured to receive events as a simple log aggregator. A Fluent Bit instance is started with the cpu monitor, and configured to send events to port 24500 with the forward plugin. Once started, it submits events to the Fluentd instance, which outputs them to stdout (which is redirected to the file aggregator.output).

$ cat aggregator.conf

<system>
  process_name aggregator
</system>
<source>
  @type forward
  port 24500
</source>
<match>
  @type stdout
</match>

$ fluentd -c aggregator.conf -o ~/aggregator.output -d .9999

$ fluent-bit -i cpu -t my_cpu -o forward://127.0.0.1:24500 &

Fluent Bit v1.0.6
Copyright (C) Treasure Data
[2021/05/07 23:18:04] [ info] [engine] started (pid=1790)
[2021/05/07 23:18:04] [ info] [storage] version=1.1.1, initializing...
[2021/05/07 23:18:04] [ info] [storage] in-memory
[2021/05/07 23:18:04] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128
[2021/05/07 23:18:04] [ info] [sp] stream processor started

$ tail -1 ~/aggregator.output

2021-05-07 23:18:12.371219199 +0000 my_cpu:
{"cpu_p":0.0,"user_p":0.0,"system_p":0.0,"cpu0.p_cpu":0.0,"cpu0.p_user":0.0,"cpu0.p_system":0.0,"cpu1.p_cpu":0.0,"cpu1.p_user":0.0,"cpu1.p_system":0.0}

When to Use Fluent Bit over Fluentd
Deciding whether to use Fluent Bit over Fluentd requires information around the use case and target environment.

Fluent Bit can be deployed on very resource-constrained or controlled hosts - such as embedded systems or containers. In these situations, it may be useful for a pre-built, statically configured Fluent Bit instance to be compiled to act as a log forwarder for a larger Fluentd deployment. It may also make sense to forego Fluentd if no heavy processing needs to occur.

Fluent Bit may be more appropriate for deployments where host-level metrics need to be collected, where Fluent Bit can act as the sole data collector and distributor, using its built-in metrics gathering features.

On the other hand, Fluent Bit's plugin library is very small compared to Fluentd. While Fluent Bit has some plugins available that cover major use cases, Fluentd's maturity and popularity have garnered it hundreds of plugins and the ability to solve almost any logging challenge. Therefore, when sophisticated log processing pipelines are required Fluent Bit will probably not be a good option.



Sample Architecture Using Fluent Bit & Fluentd
This image illustrates an example architecture where Fluent Bit supports Fluentd. On the left, there are a group of IoT Device emitting data in MQTT. Fluent Bit is especially suitable for IoT devices because of how lightweight it is compared to Fluentd. Each IoT Device runs an instance of Fluent Bit, which organizes those MQTT messages into Fluentd Events.

 

Example architecture where Fluent Bit supports Fluentd

 

The Fluentd instance can then perform additional parsing, filtering, and transformation operations and send those formatted events to other systems in the infrastructure, such as search storage and visualization with an ElasticSearch/Kibana deployment, long-term storage in a database like MongoDB, or a Kafka-powered message queue.


